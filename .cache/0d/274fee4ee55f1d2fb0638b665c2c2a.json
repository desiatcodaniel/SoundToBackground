{"id":"node_modules/@tensorflow/tfjs-layers/dist/exports_layers.js","dependencies":[{"name":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js.map","includedInParent":true,"mtime":1618542805206},{"name":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\src\\exports_layers.ts","includedInParent":true,"mtime":1618542805545},{"name":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\package.json","includedInParent":true,"mtime":1618542826354},{"name":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1618542805530},{"name":"./engine/input_layer","loc":{"line":10,"column":27},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\input_layer.js"},{"name":"./engine/topology","loc":{"line":11,"column":22},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\engine\\topology.js"},{"name":"./exports","loc":{"line":12,"column":22},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports.js"},{"name":"./layers/advanced_activations","loc":{"line":13,"column":70},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\advanced_activations.js"},{"name":"./layers/convolutional","loc":{"line":14,"column":99},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\convolutional.js"},{"name":"./layers/convolutional_depthwise","loc":{"line":15,"column":32},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\convolutional_depthwise.js"},{"name":"./layers/convolutional_recurrent","loc":{"line":16,"column":43},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\convolutional_recurrent.js"},{"name":"./layers/core","loc":{"line":17,"column":111},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\core.js"},{"name":"./layers/embeddings","loc":{"line":18,"column":26},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\embeddings.js"},{"name":"./layers/merge","loc":{"line":19,"column":75},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\merge.js"},{"name":"./layers/noise","loc":{"line":20,"column":61},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\noise.js"},{"name":"./layers/normalization","loc":{"line":21,"column":55},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\normalization.js"},{"name":"./layers/padding","loc":{"line":22,"column":30},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\padding.js"},{"name":"./layers/pooling","loc":{"line":23,"column":199},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\pooling.js"},{"name":"./layers/recurrent","loc":{"line":24,"column":102},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\recurrent.js"},{"name":"./layers/wrappers","loc":{"line":25,"column":47},"parent":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\exports_layers.js","resolved":"C:\\Users\\Daniel\\Documents\\SoundToBackground\\node_modules\\@tensorflow\\tfjs-layers\\dist\\layers\\wrappers.js"}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.inputLayer = inputLayer;\nexports.elu = elu;\nexports.reLU = reLU;\nexports.leakyReLU = leakyReLU;\nexports.prelu = prelu;\nexports.softmax = softmax;\nexports.thresholdedReLU = thresholdedReLU;\nexports.conv1d = conv1d;\nexports.conv2d = conv2d;\nexports.conv2dTranspose = conv2dTranspose;\nexports.conv3d = conv3d;\nexports.separableConv2d = separableConv2d;\nexports.cropping2D = cropping2D;\nexports.upSampling2d = upSampling2d;\nexports.depthwiseConv2d = depthwiseConv2d;\nexports.activation = activation;\nexports.dense = dense;\nexports.dropout = dropout;\nexports.spatialDropout1d = spatialDropout1d;\nexports.flatten = flatten;\nexports.repeatVector = repeatVector;\nexports.reshape = reshape;\nexports.permute = permute;\nexports.embedding = embedding;\nexports.add = add;\nexports.average = average;\nexports.concatenate = concatenate;\nexports.maximum = maximum;\nexports.minimum = minimum;\nexports.multiply = multiply;\nexports.dot = dot;\nexports.batchNormalization = batchNormalization;\nexports.layerNormalization = layerNormalization;\nexports.zeroPadding2d = zeroPadding2d;\nexports.averagePooling1d = averagePooling1d;\nexports.avgPool1d = avgPool1d;\nexports.avgPooling1d = avgPooling1d;\nexports.averagePooling2d = averagePooling2d;\nexports.avgPool2d = avgPool2d;\nexports.avgPooling2d = avgPooling2d;\nexports.averagePooling3d = averagePooling3d;\nexports.avgPool3d = avgPool3d;\nexports.avgPooling3d = avgPooling3d;\nexports.globalAveragePooling1d = globalAveragePooling1d;\nexports.globalAveragePooling2d = globalAveragePooling2d;\nexports.globalMaxPooling1d = globalMaxPooling1d;\nexports.globalMaxPooling2d = globalMaxPooling2d;\nexports.maxPooling1d = maxPooling1d;\nexports.maxPooling2d = maxPooling2d;\nexports.maxPooling3d = maxPooling3d;\nexports.gru = gru;\nexports.gruCell = gruCell;\nexports.lstm = lstm;\nexports.lstmCell = lstmCell;\nexports.simpleRNN = simpleRNN;\nexports.simpleRNNCell = simpleRNNCell;\nexports.convLstm2d = convLstm2d;\nexports.convLstm2dCell = convLstm2dCell;\nexports.rnn = rnn;\nexports.stackedRNNCells = stackedRNNCells;\nexports.bidirectional = bidirectional;\nexports.timeDistributed = timeDistributed;\nexports.gaussianNoise = gaussianNoise;\nexports.gaussianDropout = gaussianDropout;\nexports.alphaDropout = alphaDropout;\nexports.masking = masking;\nObject.defineProperty(exports, \"Layer\", {\n  enumerable: true,\n  get: function () {\n    return _topology.Layer;\n  }\n});\nObject.defineProperty(exports, \"input\", {\n  enumerable: true,\n  get: function () {\n    return _exports.input;\n  }\n});\nObject.defineProperty(exports, \"RNN\", {\n  enumerable: true,\n  get: function () {\n    return _recurrent.RNN;\n  }\n});\nObject.defineProperty(exports, \"RNNCell\", {\n  enumerable: true,\n  get: function () {\n    return _recurrent.RNNCell;\n  }\n});\nexports.maxPool2d = exports.maxPool1d = exports.globalMaxPool2d = exports.globalMaxPool1d = void 0;\n\nvar _input_layer = require(\"./engine/input_layer\");\n\nvar _topology = require(\"./engine/topology\");\n\nvar _exports = require(\"./exports\");\n\nvar _advanced_activations = require(\"./layers/advanced_activations\");\n\nvar _convolutional = require(\"./layers/convolutional\");\n\nvar _convolutional_depthwise = require(\"./layers/convolutional_depthwise\");\n\nvar _convolutional_recurrent = require(\"./layers/convolutional_recurrent\");\n\nvar _core = require(\"./layers/core\");\n\nvar _embeddings = require(\"./layers/embeddings\");\n\nvar _merge = require(\"./layers/merge\");\n\nvar _noise = require(\"./layers/noise\");\n\nvar _normalization = require(\"./layers/normalization\");\n\nvar _padding = require(\"./layers/padding\");\n\nvar _pooling = require(\"./layers/pooling\");\n\nvar _recurrent = require(\"./layers/recurrent\");\n\nvar _wrappers = require(\"./layers/wrappers\");\n\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\n// TODO(cais): Add doc string to all the public static functions in this\n//   class; include exectuable JavaScript code snippets where applicable\n//   (b/74074458).\n// Input Layer.\n\n/**\r\n * An input layer is an entry point into a `tf.LayersModel`.\r\n *\r\n * `InputLayer` is generated automatically for `tf.Sequential`` models by\r\n * specifying the `inputshape` or `batchInputShape` for the first layer.  It\r\n * should not be specified explicitly. However, it can be useful sometimes,\r\n * e.g., when constructing a sequential model from a subset of another\r\n * sequential model's layers. Like the code snippet below shows.\r\n *\r\n * ```js\r\n * // Define a model which simply adds two inputs.\r\n * const model1 = tf.sequential();\r\n * model1.add(tf.layers.dense({inputShape: [4], units: 3, activation: 'relu'}));\r\n * model1.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));\r\n * model1.summary();\r\n * model1.predict(tf.zeros([1, 4])).print();\r\n *\r\n * // Construct another model, reusing the second layer of `model1` while\r\n * // not using the first layer of `model1`. Note that you cannot add the second\r\n * // layer of `model` directly as the first layer of the new sequential model,\r\n * // because doing so will lead to an error related to the fact that the layer\r\n * // is not an input layer. Instead, you need to create an `inputLayer` and add\r\n * // it to the new sequential model before adding the reused layer.\r\n * const model2 = tf.sequential();\r\n * // Use an inputShape that matches the input shape of `model1`'s second\r\n * // layer.\r\n * model2.add(tf.layers.inputLayer({inputShape: [3]}));\r\n * model2.add(model1.layers[1]);\r\n * model2.summary();\r\n * model2.predict(tf.zeros([1, 3])).print();\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Inputs', namespace: 'layers'}\r\n */\nfunction inputLayer(args) {\n  return new _input_layer.InputLayer(args);\n} // Advanced Activation Layers.\n\n/**\r\n * Exponetial Linear Unit (ELU).\r\n *\r\n * It follows:\r\n * `f(x) =  alpha * (exp(x) - 1.) for x < 0`,\r\n * `f(x) = x for x >= 0`.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * References:\r\n *   - [Fast and Accurate Deep Network Learning by Exponential Linear Units\r\n * (ELUs)](https://arxiv.org/abs/1511.07289v1)\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\n\n\nfunction elu(args) {\n  return new _advanced_activations.ELU(args);\n}\n/**\r\n * Rectified Linear Unit activation function.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the config field `inputShape` (Array of integers, does\r\n *   not include the sample axis) when using this layer as the first layer\r\n *   in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\n\n\nfunction reLU(args) {\n  return new _advanced_activations.ReLU(args);\n}\n/**\r\n * Leaky version of a rectified linear unit.\r\n *\r\n * It allows a small gradient when the unit is not active:\r\n * `f(x) = alpha * x for x < 0.`\r\n * `f(x) = x for x >= 0.`\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\n\n\nfunction leakyReLU(args) {\n  return new _advanced_activations.LeakyReLU(args);\n}\n/**\r\n * Parameterized version of a leaky rectified linear unit.\r\n *\r\n * It follows\r\n * `f(x) = alpha * x for x < 0.`\r\n * `f(x) = x for x >= 0.`\r\n * wherein `alpha` is a trainable weight.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\n\n\nfunction prelu(args) {\n  return new _advanced_activations.PReLU(args);\n}\n/**\r\n * Softmax activation layer.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\n\n\nfunction softmax(args) {\n  return new _advanced_activations.Softmax(args);\n}\n/**\r\n * Thresholded Rectified Linear Unit.\r\n *\r\n * It follows:\r\n * `f(x) = x for x > theta`,\r\n * `f(x) = 0 otherwise`.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * References:\r\n *   - [Zero-Bias Autoencoders and the Benefits of Co-Adapting\r\n * Features](http://arxiv.org/abs/1402.3337)\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\n\n\nfunction thresholdedReLU(args) {\n  return new _advanced_activations.ThresholdedReLU(args);\n} // Convolutional Layers.\n\n/**\r\n * 1D convolution layer (e.g., temporal convolution).\r\n *\r\n * This layer creates a convolution kernel that is convolved\r\n * with the layer input over a single spatial (or temporal) dimension\r\n * to produce a tensor of outputs.\r\n *\r\n * If `use_bias` is True, a bias vector is created and added to the outputs.\r\n *\r\n * If `activation` is not `null`, it is applied to the outputs as well.\r\n *\r\n * When using this layer as the first layer in a model, provide an\r\n * `inputShape` argument `Array` or `null`.\r\n *\r\n * For example, `inputShape` would be:\r\n * - `[10, 128]` for sequences of 10 vectors of 128-dimensional vectors\r\n * - `[null, 128]` for variable-length sequences of 128-dimensional vectors.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional',  namespace: 'layers'}\r\n */\n\n\nfunction conv1d(args) {\n  return new _convolutional.Conv1D(args);\n}\n/**\r\n * 2D convolution layer (e.g. spatial convolution over images).\r\n *\r\n * This layer creates a convolution kernel that is convolved\r\n * with the layer input to produce a tensor of outputs.\r\n *\r\n * If `useBias` is True, a bias vector is created and added to the outputs.\r\n *\r\n * If `activation` is not `null`, it is applied to the outputs as well.\r\n *\r\n * When using this layer as the first layer in a model,\r\n * provide the keyword argument `inputShape`\r\n * (Array of integers, does not include the sample axis),\r\n * e.g. `inputShape=[128, 128, 3]` for 128x128 RGB pictures\r\n * in `dataFormat='channelsLast'`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\n\n\nfunction conv2d(args) {\n  return new _convolutional.Conv2D(args);\n}\n/**\r\n * Transposed convolutional layer (sometimes called Deconvolution).\r\n *\r\n * The need for transposed convolutions generally arises\r\n * from the desire to use a transformation going in the opposite direction of\r\n * a normal convolution, i.e., from something that has the shape of the output\r\n * of some convolution to something that has the shape of its input while\r\n * maintaining a connectivity pattern that is compatible with said\r\n * convolution.\r\n *\r\n * When using this layer as the first layer in a model, provide the\r\n * configuration `inputShape` (`Array` of integers, does not include the\r\n * sample axis), e.g., `inputShape: [128, 128, 3]` for 128x128 RGB pictures in\r\n * `dataFormat: 'channelsLast'`.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *   `[batch, channels, rows, cols]` if `dataFormat` is `'channelsFirst'`.\r\n *   or 4D tensor with shape\r\n *   `[batch, rows, cols, channels]` if `dataFormat` is `'channelsLast`.\r\n *\r\n * Output shape:\r\n *   4D tensor with shape:\r\n *   `[batch, filters, newRows, newCols]` if `dataFormat` is\r\n * `'channelsFirst'`. or 4D tensor with shape:\r\n *   `[batch, newRows, newCols, filters]` if `dataFormat` is `'channelsLast'`.\r\n *\r\n * References:\r\n *   - [A guide to convolution arithmetic for deep\r\n * learning](https://arxiv.org/abs/1603.07285v1)\r\n *   - [Deconvolutional\r\n * Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\n\n\nfunction conv2dTranspose(args) {\n  return new _convolutional.Conv2DTranspose(args);\n}\n/**\r\n * 3D convolution layer (e.g. spatial convolution over volumes).\r\n *\r\n * This layer creates a convolution kernel that is convolved\r\n * with the layer input to produce a tensor of outputs.\r\n *\r\n * If `useBias` is True, a bias vector is created and added to the outputs.\r\n *\r\n * If `activation` is not `null`, it is applied to the outputs as well.\r\n *\r\n * When using this layer as the first layer in a model,\r\n * provide the keyword argument `inputShape`\r\n * (Array of integers, does not include the sample axis),\r\n * e.g. `inputShape=[128, 128, 128, 1]` for 128x128x128 grayscale volumes\r\n * in `dataFormat='channelsLast'`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\n\n\nfunction conv3d(args) {\n  return new _convolutional.Conv3D(args);\n}\n/**\r\n * Depthwise separable 2D convolution.\r\n *\r\n * Separable convolution consists of first performing\r\n * a depthwise spatial convolution\r\n * (which acts on each input channel separately)\r\n * followed by a pointwise convolution which mixes together the resulting\r\n * output channels. The `depthMultiplier` argument controls how many\r\n * output channels are generated per input channel in the depthwise step.\r\n *\r\n * Intuitively, separable convolutions can be understood as\r\n * a way to factorize a convolution kernel into two smaller kernels,\r\n * or as an extreme version of an Inception block.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *     `[batch, channels, rows, cols]` if data_format='channelsFirst'\r\n *   or 4D tensor with shape:\r\n *     `[batch, rows, cols, channels]` if data_format='channelsLast'.\r\n *\r\n * Output shape:\r\n *   4D tensor with shape:\r\n *     `[batch, filters, newRows, newCols]` if data_format='channelsFirst'\r\n *   or 4D tensor with shape:\r\n *     `[batch, newRows, newCols, filters]` if data_format='channelsLast'.\r\n *     `rows` and `cols` values might have changed due to padding.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\n\n\nfunction separableConv2d(args) {\n  return new _convolutional.SeparableConv2D(args);\n}\n/**\r\n * Cropping layer for 2D input (e.g., image).\r\n *\r\n * This layer can crop an input\r\n * at the top, bottom, left and right side of an image tensor.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, rows, cols, channels]`\r\n *   - If `data_format` is `\"channels_first\"`:\r\n *     `[batch, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   4D with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, croppedRows, croppedCols, channels]`\r\n *    - If `dataFormat` is `\"channelsFirst\"`:\r\n *     `[batch, channels, croppedRows, croppedCols]`.\r\n *\r\n * Examples\r\n * ```js\r\n *\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.cropping2D({cropping:[[2, 2], [2, 2]],\r\n *                                inputShape: [128, 128, 3]}));\r\n * //now output shape is [batch, 124, 124, 3]\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\n\n\nfunction cropping2D(args) {\n  return new _convolutional.Cropping2D(args);\n}\n/**\r\n * Upsampling layer for 2D inputs.\r\n *\r\n * Repeats the rows and columns of the data\r\n * by size[0] and size[1] respectively.\r\n *\r\n *\r\n * Input shape:\r\n *    4D tensor with shape:\r\n *     - If `dataFormat` is `\"channelsLast\"`:\r\n *         `[batch, rows, cols, channels]`\r\n *     - If `dataFormat` is `\"channelsFirst\"`:\r\n *        `[batch, channels, rows, cols]`\r\n *\r\n * Output shape:\r\n *     4D tensor with shape:\r\n *     - If `dataFormat` is `\"channelsLast\"`:\r\n *        `[batch, upsampledRows, upsampledCols, channels]`\r\n *     - If `dataFormat` is `\"channelsFirst\"`:\r\n *         `[batch, channels, upsampledRows, upsampledCols]`\r\n *\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\n\n\nfunction upSampling2d(args) {\n  return new _convolutional.UpSampling2D(args);\n} // Convolutional(depthwise) Layers.\n\n/**\r\n * Depthwise separable 2D convolution.\r\n *\r\n * Depthwise Separable convolutions consists in performing just the first step\r\n * in a depthwise spatial convolution (which acts on each input channel\r\n * separately). The `depthMultplier` argument controls how many output channels\r\n * are generated per input channel in the depthwise step.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\n\n\nfunction depthwiseConv2d(args) {\n  return new _convolutional_depthwise.DepthwiseConv2D(args);\n} // Basic Layers.\n\n/**\r\n * Applies an activation function to an output.\r\n *\r\n * This layer applies element-wise activation function.  Other layers, notably\r\n * `dense` can also apply activation functions.  Use this isolated activation\r\n * function to extract the values before and after the\r\n * activation. For instance:\r\n *\r\n * ```js\r\n * const input = tf.input({shape: [5]});\r\n * const denseLayer = tf.layers.dense({units: 1});\r\n * const activationLayer = tf.layers.activation({activation: 'relu6'});\r\n *\r\n * // Obtain the output symbolic tensors by applying the layers in order.\r\n * const denseOutput = denseLayer.apply(input);\r\n * const activationOutput = activationLayer.apply(denseOutput);\r\n *\r\n * // Create the model based on the inputs.\r\n * const model = tf.model({\r\n *     inputs: input,\r\n *     outputs: [denseOutput, activationOutput]\r\n * });\r\n *\r\n * // Collect both outputs and print separately.\r\n * const [denseOut, activationOut] = model.predict(tf.randomNormal([6, 5]));\r\n * denseOut.print();\r\n * activationOut.print();\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction activation(args) {\n  return new _core.Activation(args);\n}\n/**\r\n * Creates a dense (fully connected) layer.\r\n *\r\n * This layer implements the operation:\r\n *   `output = activation(dot(input, kernel) + bias)`\r\n *\r\n * `activation` is the element-wise activation function\r\n *   passed as the `activation` argument.\r\n *\r\n * `kernel` is a weights matrix created by the layer.\r\n *\r\n * `bias` is a bias vector created by the layer (only applicable if `useBias`\r\n * is `true`).\r\n *\r\n * **Input shape:**\r\n *\r\n *   nD `tf.Tensor` with shape: `(batchSize, ..., inputDim)`.\r\n *\r\n *   The most common situation would be\r\n *   a 2D input with shape `(batchSize, inputDim)`.\r\n *\r\n * **Output shape:**\r\n *\r\n *   nD tensor with shape: `(batchSize, ..., units)`.\r\n *\r\n *   For instance, for a 2D input with shape `(batchSize, inputDim)`,\r\n *   the output would have shape `(batchSize, units)`.\r\n *\r\n * Note: if the input to the layer has a rank greater than 2, then it is\r\n * flattened prior to the initial dot product with the kernel.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction dense(args) {\n  return new _core.Dense(args);\n}\n/**\r\n * Applies\r\n * [dropout](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf) to\r\n * the input.\r\n *\r\n * Dropout consists in randomly setting a fraction `rate` of input units to 0 at\r\n * each update during training time, which helps prevent overfitting.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction dropout(args) {\n  return new _core.Dropout(args);\n}\n/**\r\n * Spatial 1D version of Dropout.\r\n *\r\n * This Layer type performs the same function as the Dropout layer, but it drops\r\n * entire 1D feature maps instead of individual elements. For example, if an\r\n * input example consists of 3 timesteps and the feature map for each timestep\r\n * has a size of 4, a `spatialDropout1d` layer may zero out the feature maps\r\n * of the 1st timesteps and 2nd timesteps completely while sparing all feature\r\n * elements of the 3rd timestep.\r\n *\r\n * If adjacent frames (timesteps) are strongly correlated (as is normally the\r\n * case in early convolution layers), regular dropout will not regularize the\r\n * activation and will otherwise just result in merely an effective learning\r\n * rate decrease. In this case, `spatialDropout1d` will help promote\r\n * independence among feature maps and should be used instead.\r\n *\r\n * **Arguments:**\r\n *   rate: A floating-point number >=0 and <=1. Fraction of the input elements\r\n *     to drop.\r\n *\r\n * **Input shape:**\r\n *   3D tensor with shape `(samples, timesteps, channels)`.\r\n *\r\n * **Output shape:**\r\n *   Same as the input shape.\r\n *\r\n * References:\r\n *   - [Efficient Object Localization Using Convolutional\r\n *      Networks](https://arxiv.org/abs/1411.4280)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction spatialDropout1d(args) {\n  return new _core.SpatialDropout1D(args);\n}\n/**\r\n * Flattens the input. Does not affect the batch size.\r\n *\r\n * A `Flatten` layer flattens each batch in its inputs to 1D (making the output\r\n * 2D).\r\n *\r\n * For example:\r\n *\r\n * ```js\r\n * const input = tf.input({shape: [4, 3]});\r\n * const flattenLayer = tf.layers.flatten();\r\n * // Inspect the inferred output shape of the flatten layer, which\r\n * // equals `[null, 12]`. The 2nd dimension is 4 * 3, i.e., the result of the\r\n * // flattening. (The 1st dimension is the undermined batch size.)\r\n * console.log(JSON.stringify(flattenLayer.apply(input).shape));\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction flatten(args) {\n  return new _core.Flatten(args);\n}\n/**\r\n * Repeats the input n times in a new dimension.\r\n *\r\n * ```js\r\n *  const model = tf.sequential();\r\n *  model.add(tf.layers.repeatVector({n: 4, inputShape: [2]}));\r\n *  const x = tf.tensor2d([[10, 20]]);\r\n *  // Use the model to do inference on a data point the model hasn't see\r\n *  model.predict(x).print();\r\n *  // output shape is now [batch, 2, 4]\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction repeatVector(args) {\n  return new _core.RepeatVector(args);\n}\n/**\r\n * Reshapes an input to a certain shape.\r\n *\r\n * ```js\r\n * const input = tf.input({shape: [4, 3]});\r\n * const reshapeLayer = tf.layers.reshape({targetShape: [2, 6]});\r\n * // Inspect the inferred output shape of the Reshape layer, which\r\n * // equals `[null, 2, 6]`. (The 1st dimension is the undermined batch size.)\r\n * console.log(JSON.stringify(reshapeLayer.apply(input).shape));\r\n * ```\r\n *\r\n * Input shape:\r\n *   Arbitrary, although all dimensions in the input shape must be fixed.\r\n *   Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n *\r\n * Output shape:\r\n *   [batchSize, targetShape[0], targetShape[1], ...,\r\n *    targetShape[targetShape.length - 1]].\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction reshape(args) {\n  return new _core.Reshape(args);\n}\n/**\r\n * Permutes the dimensions of the input according to a given pattern.\r\n *\r\n * Useful for, e.g., connecting RNNs and convnets together.\r\n *\r\n * Example:\r\n *\r\n * ```js\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.permute({\r\n *   dims: [2, 1],\r\n *   inputShape: [10, 64]\r\n * }));\r\n * console.log(model.outputShape);\r\n * // Now model's output shape is [null, 64, 10], where null is the\r\n * // unpermuted sample (batch) dimension.\r\n * ```\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration field `inputShape` when using this\r\n *   layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same rank as the input shape, but with the dimensions re-ordered (i.e.,\r\n *   permuted) according to the `dims` configuration of this layer.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction permute(args) {\n  return new _core.Permute(args);\n}\n/**\r\n * Maps positive integers (indices) into dense vectors of fixed size.\r\n * eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\r\n *\r\n * **Input shape:** 2D tensor with shape: `[batchSize, sequenceLength]`.\r\n *\r\n * **Output shape:** 3D tensor with shape: `[batchSize, sequenceLength,\r\n * outputDim]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\n\n\nfunction embedding(args) {\n  return new _embeddings.Embedding(args);\n} // Merge Layers.\n\n/**\r\n * Layer that performs element-wise addition on an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape, and returns a\r\n * single tensor (also of the same shape). The inputs are specified as an\r\n * `Array` when the `apply` method of the `Add` layer instance is called. For\r\n * example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const addLayer = tf.layers.add();\r\n * const sum = addLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(sum.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\n\n\nfunction add(args) {\n  return new _merge.Add(args);\n}\n/**\r\n * Layer that performs element-wise averaging on an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape, and returns a\r\n * single tensor (also of the same shape). For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const averageLayer = tf.layers.average();\r\n * const average = averageLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(average.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\n\n\nfunction average(args) {\n  return new _merge.Average(args);\n}\n/**\r\n * Layer that concatenates an `Array` of inputs.\r\n *\r\n * It takes a list of tensors, all of the same shape except for the\r\n * concatenation axis, and returns a single tensor, the concatenation\r\n * of all inputs. For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 3]});\r\n * const concatLayer = tf.layers.concatenate();\r\n * const output = concatLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(output.shape));\r\n * // You get [null, 2, 5], with the first dimension as the undetermined batch\r\n * // dimension. The last dimension (5) is the result of concatenating the\r\n * // last dimensions of the inputs (2 and 3).\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\n\n\nfunction concatenate(args) {\n  return new _merge.Concatenate(args);\n}\n/**\r\n * Layer that computes the element-wise maximum an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape and returns a\r\n * single tensor (also of the same shape). For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const maxLayer = tf.layers.maximum();\r\n * const max = maxLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(max.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\n\n\nfunction maximum(args) {\n  return new _merge.Maximum(args);\n}\n/**\r\n * Layer that computes the element-wise minimum of an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape and returns a\r\n * single tensor (also of the same shape). For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const minLayer = tf.layers.minimum();\r\n * const min = minLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(min.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\n\n\nfunction minimum(args) {\n  return new _merge.Minimum(args);\n}\n/**\r\n * Layer that multiplies (element-wise) an `Array` of inputs.\r\n *\r\n * It takes as input an Array of tensors, all of the same\r\n * shape, and returns a single tensor (also of the same shape).\r\n * For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const input3 = tf.input({shape: [2, 2]});\r\n * const multiplyLayer = tf.layers.multiply();\r\n * const product = multiplyLayer.apply([input1, input2, input3]);\r\n * console.log(product.shape);\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\n\n\nfunction multiply(args) {\n  return new _merge.Multiply(args);\n}\n/**\r\n * Layer that computes a dot product between samples in two tensors.\r\n *\r\n * E.g., if applied to a list of two tensors `a` and `b` both of shape\r\n * `[batchSize, n]`, the output will be a tensor of shape `[batchSize, 1]`,\r\n * where each entry at index `[i, 0]` will be the dot product between\r\n * `a[i, :]` and `b[i, :]`.\r\n *\r\n * Example:\r\n *\r\n * ```js\r\n * const dotLayer = tf.layers.dot({axes: -1});\r\n * const x1 = tf.tensor2d([[10, 20], [30, 40]]);\r\n * const x2 = tf.tensor2d([[-1, -2], [-3, -4]]);\r\n *\r\n * // Invoke the layer's apply() method in eager (imperative) mode.\r\n * const y = dotLayer.apply([x1, x2]);\r\n * y.print();\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\n\n\nfunction dot(args) {\n  return new _merge.Dot(args);\n} // Normalization Layers.\n\n/**\r\n * Batch normalization layer (Ioffe and Szegedy, 2014).\r\n *\r\n * Normalize the activations of the previous layer at each batch,\r\n * i.e. applies a transformation that maintains the mean activation\r\n * close to 0 and the activation standard deviation close to 1.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape` (Array of integers, does\r\n *   not include the sample axis) when calling the constructor of this class,\r\n *   if this layer is used as a first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * References:\r\n *   - [Batch Normalization: Accelerating Deep Network Training by Reducing\r\n * Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Normalization', namespace: 'layers'}\r\n */\n\n\nfunction batchNormalization(args) {\n  return new _normalization.BatchNormalization(args);\n}\n/**\r\n * Layer-normalization layer (Ba et al., 2016).\r\n *\r\n * Normalizes the activations of the previous layer for each given example in a\r\n * batch independently, instead of across a batch like in `batchNormalization`.\r\n * In other words, this layer applies a transformation that maintanis the mean\r\n * activation within each example close to0 and activation variance close to 1.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the argument `inputShape` when using this layer as the first\r\n *   layer in a model.\r\n *\r\n * Output shape:\r\n *   Same as input.\r\n *\r\n * References:\r\n *   - [Layer Normalization](https://arxiv.org/abs/1607.06450)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Normalization', namespace: 'layers'}\r\n */\n\n\nfunction layerNormalization(args) {\n  return new _normalization.LayerNormalization(args);\n} // Padding Layers.\n\n/**\r\n * Zero-padding layer for 2D input (e.g., image).\r\n *\r\n * This layer can add rows and columns of zeros\r\n * at the top, bottom, left and right side of an image tensor.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, rows, cols, channels]`\r\n *   - If `data_format` is `\"channels_first\"`:\r\n *     `[batch, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   4D with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, paddedRows, paddedCols, channels]`\r\n *    - If `dataFormat` is `\"channelsFirst\"`:\r\n *     `[batch, channels, paddedRows, paddedCols]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Padding', namespace: 'layers'}\r\n */\n\n\nfunction zeroPadding2d(args) {\n  return new _padding.ZeroPadding2D(args);\n} // Pooling Layers.\n\n/**\r\n * Average pooling operation for spatial data.\r\n *\r\n * Input shape: `[batchSize, inLength, channels]`\r\n *\r\n * Output shape: `[batchSize, pooledLength, channels]`\r\n *\r\n * `tf.avgPool1d` is an alias.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction averagePooling1d(args) {\n  return new _pooling.AveragePooling1D(args);\n}\n\nfunction avgPool1d(args) {\n  return averagePooling1d(args);\n} // For backwards compatibility.\n// See https://github.com/tensorflow/tfjs/issues/152\n\n\nfunction avgPooling1d(args) {\n  return averagePooling1d(args);\n}\n/**\r\n * Average pooling operation for spatial data.\r\n *\r\n * Input shape:\r\n *  - If `dataFormat === CHANNEL_LAST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, rows, cols, channels]`\r\n *  - If `dataFormat === CHANNEL_FIRST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, channels, rows, cols]`\r\n *\r\n * Output shape\r\n *  - If `dataFormat === CHANNEL_LAST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, pooleRows, pooledCols, channels]`\r\n *  - If `dataFormat === CHANNEL_FIRST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, channels, pooleRows, pooledCols]`\r\n *\r\n * `tf.avgPool2d` is an alias.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction averagePooling2d(args) {\n  return new _pooling.AveragePooling2D(args);\n}\n\nfunction avgPool2d(args) {\n  return averagePooling2d(args);\n} // For backwards compatibility.\n// See https://github.com/tensorflow/tfjs/issues/152\n\n\nfunction avgPooling2d(args) {\n  return averagePooling2d(args);\n}\n/**\r\n * Average pooling operation for 3D data.\r\n *\r\n * Input shape\r\n *   - If `dataFormat === channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, depths, rows, cols, channels]`\r\n *   - If `dataFormat === channelsFirst`:\r\n *      4D tensor with shape:\r\n *       `[batchSize, channels, depths, rows, cols]`\r\n *\r\n * Output shape\r\n *   - If `dataFormat=channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, pooledDepths, pooledRows, pooledCols, channels]`\r\n *   - If `dataFormat=channelsFirst`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, channels, pooledDepths, pooledRows, pooledCols]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction averagePooling3d(args) {\n  return new _pooling.AveragePooling3D(args);\n}\n\nfunction avgPool3d(args) {\n  return averagePooling3d(args);\n} // For backwards compatibility.\n// See https://github.com/tensorflow/tfjs/issues/152\n\n\nfunction avgPooling3d(args) {\n  return averagePooling3d(args);\n}\n/**\r\n * Global average pooling operation for temporal data.\r\n *\r\n * Input Shape: 3D tensor with shape: `[batchSize, steps, features]`.\r\n *\r\n * Output Shape:2D tensor with shape: `[batchSize, features]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction globalAveragePooling1d(args) {\n  return new _pooling.GlobalAveragePooling1D(args);\n}\n/**\r\n * Global average pooling operation for spatial data.\r\n *\r\n * Input shape:\r\n *   - If `dataFormat` is `CHANNEL_LAST`:\r\n *       4D tensor with shape: `[batchSize, rows, cols, channels]`.\r\n *   - If `dataFormat` is `CHANNEL_FIRST`:\r\n *       4D tensor with shape: `[batchSize, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   2D tensor with shape: `[batchSize, channels]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction globalAveragePooling2d(args) {\n  return new _pooling.GlobalAveragePooling2D(args);\n}\n/**\r\n * Global max pooling operation for temporal data.\r\n *\r\n * Input Shape: 3D tensor with shape: `[batchSize, steps, features]`.\r\n *\r\n * Output Shape:2D tensor with shape: `[batchSize, features]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction globalMaxPooling1d(args) {\n  return new _pooling.GlobalMaxPooling1D(args);\n}\n/**\r\n * Global max pooling operation for spatial data.\r\n *\r\n * Input shape:\r\n *   - If `dataFormat` is `CHANNEL_LAST`:\r\n *       4D tensor with shape: `[batchSize, rows, cols, channels]`.\r\n *   - If `dataFormat` is `CHANNEL_FIRST`:\r\n *       4D tensor with shape: `[batchSize, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   2D tensor with shape: `[batchSize, channels]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction globalMaxPooling2d(args) {\n  return new _pooling.GlobalMaxPooling2D(args);\n}\n/**\r\n * Max pooling operation for temporal data.\r\n *\r\n * Input shape:  `[batchSize, inLength, channels]`\r\n *\r\n * Output shape: `[batchSize, pooledLength, channels]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction maxPooling1d(args) {\n  return new _pooling.MaxPooling1D(args);\n}\n/**\r\n * Max pooling operation for spatial data.\r\n *\r\n * Input shape\r\n *   - If `dataFormat === CHANNEL_LAST`:\r\n *       4D tensor with shape:\r\n *       `[batchSize, rows, cols, channels]`\r\n *   - If `dataFormat === CHANNEL_FIRST`:\r\n *      4D tensor with shape:\r\n *       `[batchSize, channels, rows, cols]`\r\n *\r\n * Output shape\r\n *   - If `dataFormat=CHANNEL_LAST`:\r\n *       4D tensor with shape:\r\n *       `[batchSize, pooleRows, pooledCols, channels]`\r\n *   - If `dataFormat=CHANNEL_FIRST`:\r\n *       4D tensor with shape:\r\n *       `[batchSize, channels, pooleRows, pooledCols]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction maxPooling2d(args) {\n  return new _pooling.MaxPooling2D(args);\n}\n/**\r\n * Max pooling operation for 3D data.\r\n *\r\n * Input shape\r\n *   - If `dataFormat === channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, depths, rows, cols, channels]`\r\n *   - If `dataFormat === channelsFirst`:\r\n *      5D tensor with shape:\r\n *       `[batchSize, channels, depths, rows, cols]`\r\n *\r\n * Output shape\r\n *   - If `dataFormat=channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, pooledDepths, pooledRows, pooledCols, channels]`\r\n *   - If `dataFormat=channelsFirst`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, channels, pooledDepths, pooledRows, pooledCols]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\n\n\nfunction maxPooling3d(args) {\n  return new _pooling.MaxPooling3D(args);\n} // Recurrent Layers.\n\n/**\r\n * Gated Recurrent Unit - Cho et al. 2014.\r\n *\r\n * This is an `RNN` layer consisting of one `GRUCell`. However, unlike\r\n * the underlying `GRUCell`, the `apply` method of `SimpleRNN` operates\r\n * on a sequence of inputs. The shape of the input (not including the first,\r\n * batch dimension) needs to be at least 2-D, with the first dimension being\r\n * time steps. For example:\r\n *\r\n * ```js\r\n * const rnn = tf.layers.gru({units: 8, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the `GRUCell`'s number of units.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction gru(args) {\n  return new _recurrent.GRU(args);\n}\n/**\r\n * Cell class for `GRU`.\r\n *\r\n * `GRUCell` is distinct from the `RNN` subclass `GRU` in that its\r\n * `apply` method takes the input data of only a single time step and returns\r\n * the cell's output at the time step, while `GRU` takes the input data\r\n * over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const cell = tf.layers.gruCell({units: 2});\r\n * const input = tf.input({shape: [10]});\r\n * const output = cell.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10]: This is the cell's output at a single time step. The 1st\r\n * // dimension is the unknown batch size.\r\n * ```\r\n *\r\n * Instance(s) of `GRUCell` can be used to construct `RNN` layers. The\r\n * most typical use of this workflow is to combine a number of cells into a\r\n * stacked RNN cell (i.e., `StackedRNNCell` internally) and use it to create an\r\n * RNN. For example:\r\n *\r\n * ```js\r\n * const cells = [\r\n *   tf.layers.gruCell({units: 4}),\r\n *   tf.layers.gruCell({units: 8}),\r\n * ];\r\n * const rnn = tf.layers.rnn({cell: cells, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps and a length-20 vector at each step.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the last `gruCell`'s number of units.\r\n * ```\r\n *\r\n * To create an `RNN` consisting of only *one* `GRUCell`, use the\r\n * `tf.layers.gru`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction gruCell(args) {\n  return new _recurrent.GRUCell(args);\n}\n/**\r\n * Long-Short Term Memory layer - Hochreiter 1997.\r\n *\r\n * This is an `RNN` layer consisting of one `LSTMCell`. However, unlike\r\n * the underlying `LSTMCell`, the `apply` method of `LSTM` operates\r\n * on a sequence of inputs. The shape of the input (not including the first,\r\n * batch dimension) needs to be at least 2-D, with the first dimension being\r\n * time steps. For example:\r\n *\r\n * ```js\r\n * const lstm = tf.layers.lstm({units: 8, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = lstm.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the `LSTMCell`'s number of units.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction lstm(args) {\n  return new _recurrent.LSTM(args);\n}\n/**\r\n * Cell class for `LSTM`.\r\n *\r\n * `LSTMCell` is distinct from the `RNN` subclass `LSTM` in that its\r\n * `apply` method takes the input data of only a single time step and returns\r\n * the cell's output at the time step, while `LSTM` takes the input data\r\n * over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const cell = tf.layers.lstmCell({units: 2});\r\n * const input = tf.input({shape: [10]});\r\n * const output = cell.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10]: This is the cell's output at a single time step. The 1st\r\n * // dimension is the unknown batch size.\r\n * ```\r\n *\r\n * Instance(s) of `LSTMCell` can be used to construct `RNN` layers. The\r\n * most typical use of this workflow is to combine a number of cells into a\r\n * stacked RNN cell (i.e., `StackedRNNCell` internally) and use it to create an\r\n * RNN. For example:\r\n *\r\n * ```js\r\n * const cells = [\r\n *   tf.layers.lstmCell({units: 4}),\r\n *   tf.layers.lstmCell({units: 8}),\r\n * ];\r\n * const rnn = tf.layers.rnn({cell: cells, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps and a length-20 vector at each step.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the last `lstmCell`'s number of units.\r\n * ```\r\n *\r\n * To create an `RNN` consisting of only *one* `LSTMCell`, use the\r\n * `tf.layers.lstm`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction lstmCell(args) {\n  return new _recurrent.LSTMCell(args);\n}\n/**\r\n * Fully-connected RNN where the output is to be fed back to input.\r\n *\r\n * This is an `RNN` layer consisting of one `SimpleRNNCell`. However, unlike\r\n * the underlying `SimpleRNNCell`, the `apply` method of `SimpleRNN` operates\r\n * on a sequence of inputs. The shape of the input (not including the first,\r\n * batch dimension) needs to be at least 2-D, with the first dimension being\r\n * time steps. For example:\r\n *\r\n * ```js\r\n * const rnn = tf.layers.simpleRNN({units: 8, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the `SimpleRNNCell`'s number of units.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction simpleRNN(args) {\n  return new _recurrent.SimpleRNN(args);\n}\n/**\r\n * Cell class for `SimpleRNN`.\r\n *\r\n * `SimpleRNNCell` is distinct from the `RNN` subclass `SimpleRNN` in that its\r\n * `apply` method takes the input data of only a single time step and returns\r\n * the cell's output at the time step, while `SimpleRNN` takes the input data\r\n * over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const cell = tf.layers.simpleRNNCell({units: 2});\r\n * const input = tf.input({shape: [10]});\r\n * const output = cell.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10]: This is the cell's output at a single time step. The 1st\r\n * // dimension is the unknown batch size.\r\n * ```\r\n *\r\n * Instance(s) of `SimpleRNNCell` can be used to construct `RNN` layers. The\r\n * most typical use of this workflow is to combine a number of cells into a\r\n * stacked RNN cell (i.e., `StackedRNNCell` internally) and use it to create an\r\n * RNN. For example:\r\n *\r\n * ```js\r\n * const cells = [\r\n *   tf.layers.simpleRNNCell({units: 4}),\r\n *   tf.layers.simpleRNNCell({units: 8}),\r\n * ];\r\n * const rnn = tf.layers.rnn({cell: cells, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps and a length-20 vector at each step.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the last `SimpleRNNCell`'s number of units.\r\n * ```\r\n *\r\n * To create an `RNN` consisting of only *one* `SimpleRNNCell`, use the\r\n * `tf.layers.simpleRNN`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction simpleRNNCell(args) {\n  return new _recurrent.SimpleRNNCell(args);\n}\n/**\r\n * Convolutional LSTM layer - Xingjian Shi 2015.\r\n *\r\n * This is an `ConvRNN2D` layer consisting of one `ConvLSTM2DCell`. However,\r\n * unlike the underlying `ConvLSTM2DCell`, the `apply` method of `ConvLSTM2D`\r\n * operates on a sequence of inputs. The shape of the input (not including the\r\n * first, batch dimension) needs to be 4-D, with the first dimension being time\r\n * steps. For example:\r\n *\r\n * ```js\r\n * const filters = 3;\r\n * const kernelSize = 3;\r\n *\r\n * const batchSize = 4;\r\n * const sequenceLength = 2;\r\n * const size = 5;\r\n * const channels = 3;\r\n *\r\n * const inputShape = [batchSize, sequenceLength, size, size, channels];\r\n * const input = tf.ones(inputShape);\r\n *\r\n * const layer = tf.layers.convLstm2d({filters, kernelSize});\r\n *\r\n * const output = layer.apply(input);\r\n * ```\r\n */\n\n/** @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'} */\n\n\nfunction convLstm2d(args) {\n  return new _convolutional_recurrent.ConvLSTM2D(args);\n}\n/**\r\n * Cell class for `ConvLSTM2D`.\r\n *\r\n * `ConvLSTM2DCell` is distinct from the `ConvRNN2D` subclass `ConvLSTM2D` in\r\n * that its `call` method takes the input data of only a single time step and\r\n * returns the cell's output at the time step, while `ConvLSTM2D` takes the\r\n * input data over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const filters = 3;\r\n * const kernelSize = 3;\r\n *\r\n * const sequenceLength = 1;\r\n * const size = 5;\r\n * const channels = 3;\r\n *\r\n * const inputShape = [sequenceLength, size, size, channels];\r\n * const input = tf.ones(inputShape);\r\n *\r\n * const cell = tf.layers.convLstm2dCell({filters, kernelSize});\r\n *\r\n * cell.build(input.shape);\r\n *\r\n * const outputSize = size - kernelSize + 1;\r\n * const outShape = [sequenceLength, outputSize, outputSize, filters];\r\n *\r\n * const initialH = tf.zeros(outShape);\r\n * const initialC = tf.zeros(outShape);\r\n *\r\n * const [o, h, c] = cell.call([input, initialH, initialC], {});\r\n * ```\r\n */\n\n/** @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'} */\n\n\nfunction convLstm2dCell(args) {\n  return new _convolutional_recurrent.ConvLSTM2DCell(args);\n}\n/**\r\n * Base class for recurrent layers.\r\n *\r\n * Input shape:\r\n *   3D tensor with shape `[batchSize, timeSteps, inputDim]`.\r\n *\r\n * Output shape:\r\n *   - if `returnState`, an Array of tensors (i.e., `tf.Tensor`s). The first\r\n *     tensor is the output. The remaining tensors are the states at the\r\n *     last time step, each with shape `[batchSize, units]`.\r\n *   - if `returnSequences`, the output will have shape\r\n *     `[batchSize, timeSteps, units]`.\r\n *   - else, the output will have shape `[batchSize, units]`.\r\n *\r\n * Masking:\r\n *   This layer supports masking for input data with a variable number\r\n *   of timesteps. To introduce masks to your data,\r\n *   use an embedding layer with the `mask_zero` parameter\r\n *   set to `True`.\r\n *\r\n * Notes on using statefulness in RNNs:\r\n *   You can set RNN layers to be 'stateful', which means that the states\r\n *   computed for the samples in one batch will be reused as initial states\r\n *   for the samples in the next batch. This assumes a one-to-one mapping\r\n *   between samples in different successive batches.\r\n *\r\n *   To enable statefulness:\r\n *     - specify `stateful: true` in the layer constructor.\r\n *     - specify a fixed batch size for your model, by passing\r\n *       if sequential model:\r\n *         `batchInputShape=[...]` to the first layer in your model.\r\n *       else for functional model with 1 or more Input layers:\r\n *         `batchShape=[...]` to all the first layers in your model.\r\n *       This is the expected shape of your inputs *including the batch size*.\r\n *       It should be a tuple of integers, e.g. `(32, 10, 100)`.\r\n *     - specify `shuffle=False` when calling fit().\r\n *\r\n *   To reset the states of your model, call `.resetStates()` on either\r\n *   a specific layer, or on your entire model.\r\n *\r\n * Note on specifying the initial state of RNNs\r\n *   You can specify the initial state of RNN layers symbolically by\r\n *   calling them with the option `initialState`. The value of\r\n *   `initialState` should be a tensor or list of tensors representing\r\n *   the initial state of the RNN layer.\r\n *\r\n *   You can specify the initial state of RNN layers numerically by\r\n *   calling `resetStates` with the keyword argument `states`. The value of\r\n *   `states` should be a numpy array or list of numpy arrays representing\r\n *   the initial state of the RNN layer.\r\n *\r\n * Note on passing external constants to RNNs\r\n *   You can pass \"external\" constants to the cell using the `constants`\r\n *   keyword argument of `RNN.call` method. This requires that the `cell.call`\r\n *   method accepts the same keyword argument `constants`. Such constants\r\n *   can be used to conditon the cell transformation on additional static inputs\r\n *   (not changing over time), a.k.a an attention mechanism.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction rnn(args) {\n  return new _recurrent.RNN(args);\n}\n/**\r\n * Wrapper allowing a stack of RNN cells to behave as a single cell.\r\n *\r\n * Used to implement efficient stacked RNNs.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\n\n\nfunction stackedRNNCells(args) {\n  return new _recurrent.StackedRNNCells(args);\n} // Wrapper Layers.\n\n/** @doc {heading: 'Layers', subheading: 'Wrapper', namespace: 'layers'} */\n\n\nfunction bidirectional(args) {\n  return new _wrappers.Bidirectional(args);\n}\n/**\r\n * This wrapper applies a layer to every temporal slice of an input.\r\n *\r\n * The input should be at least 3D,  and the dimension of the index `1` will be\r\n * considered to be the temporal dimension.\r\n *\r\n * Consider a batch of 32 samples, where each sample is a sequence of 10 vectors\r\n * of 16 dimensions. The batch input shape of the layer is then `[32,  10,\r\n * 16]`, and the `inputShape`, not including the sample dimension, is\r\n * `[10, 16]`.\r\n *\r\n * You can then use `TimeDistributed` to apply a `Dense` layer to each of the 10\r\n * timesteps, independently:\r\n *\r\n * ```js\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.timeDistributed({\r\n *   layer: tf.layers.dense({units: 8}),\r\n *   inputShape: [10, 16],\r\n * }));\r\n *\r\n * // Now model.outputShape = [null, 10, 8].\r\n * // The output will then have shape `[32, 10, 8]`.\r\n *\r\n * // In subsequent layers, there is no need for `inputShape`:\r\n * model.add(tf.layers.timeDistributed({layer: tf.layers.dense({units: 32})}));\r\n * console.log(JSON.stringify(model.outputs[0].shape));\r\n * // Now model.outputShape = [null, 10, 32].\r\n * ```\r\n *\r\n * The output will then have shape `[32, 10, 32]`.\r\n *\r\n * `TimeDistributed` can be used with arbitrary layers, not just `Dense`, for\r\n * instance a `Conv2D` layer.\r\n *\r\n * ```js\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.timeDistributed({\r\n *   layer: tf.layers.conv2d({filters: 64, kernelSize: [3, 3]}),\r\n *   inputShape: [10, 299, 299, 3],\r\n * }));\r\n * console.log(JSON.stringify(model.outputs[0].shape));\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Wrapper', namespace: 'layers'}\r\n */\n\n\nfunction timeDistributed(args) {\n  return new _wrappers.TimeDistributed(args);\n} // Aliases for pooling.\n\n\nconst globalMaxPool1d = globalMaxPooling1d;\nexports.globalMaxPool1d = globalMaxPool1d;\nconst globalMaxPool2d = globalMaxPooling2d;\nexports.globalMaxPool2d = globalMaxPool2d;\nconst maxPool1d = maxPooling1d;\nexports.maxPool1d = maxPool1d;\nconst maxPool2d = maxPooling2d;\nexports.maxPool2d = maxPool2d;\n\n/**\r\n * Apply additive zero-centered Gaussian noise.\r\n *\r\n * As it is a regularization layer, it is only active at training time.\r\n *\r\n * This is useful to mitigate overfitting\r\n * (you could see it as a form of random data augmentation).\r\n * Gaussian Noise (GS) is a natural choice as corruption process\r\n * for real valued inputs.\r\n *\r\n * # Arguments\r\n *     stddev: float, standard deviation of the noise distribution.\r\n *\r\n * # Input shape\r\n *         Arbitrary. Use the keyword argument `input_shape`\r\n *         (tuple of integers, does not include the samples axis)\r\n *         when using this layer as the first layer in a model.\r\n *\r\n * # Output shape\r\n *         Same shape as input.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Noise', namespace: 'layers'}\r\n */\nfunction gaussianNoise(args) {\n  return new _noise.GaussianNoise(args);\n}\n/**\r\n * Apply multiplicative 1-centered Gaussian noise.\r\n *\r\n * As it is a regularization layer, it is only active at training time.\r\n *\r\n * Arguments:\r\n *   - `rate`: float, drop probability (as with `Dropout`).\r\n *     The multiplicative noise will have\r\n *     standard deviation `sqrt(rate / (1 - rate))`.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape`\r\n *   (tuple of integers, does not include the samples axis)\r\n *   when using this layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * References:\r\n *   - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\r\n *      http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Noise', namespace: 'layers'}\r\n */\n\n\nfunction gaussianDropout(args) {\n  return new _noise.GaussianDropout(args);\n}\n/**\r\n * Applies Alpha Dropout to the input.\r\n *\r\n * As it is a regularization layer, it is only active at training time.\r\n *\r\n * Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\r\n * to their original values, in order to ensure the self-normalizing property\r\n * even after this dropout.\r\n * Alpha Dropout fits well to Scaled Exponential Linear Units\r\n * by randomly setting activations to the negative saturation value.\r\n *\r\n * Arguments:\r\n *   - `rate`: float, drop probability (as with `Dropout`).\r\n *     The multiplicative noise will have\r\n *     standard deviation `sqrt(rate / (1 - rate))`.\r\n *   - `noise_shape`: A 1-D `Tensor` of type `int32`, representing the\r\n *     shape for randomly generated keep/drop flags.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape`\r\n *   (tuple of integers, does not include the samples axis)\r\n *   when using this layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * References:\r\n *   - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Noise', namespace: 'layers'}\r\n */\n\n\nfunction alphaDropout(args) {\n  return new _noise.AlphaDropout(args);\n}\n/**\r\n * Masks a sequence by using a mask value to skip timesteps.\r\n *\r\n * If all features for a given sample timestep are equal to `mask_value`,\r\n * then the sample timestep will be masked (skipped) in all downstream layers\r\n * (as long as they support masking).\r\n *\r\n * If any downstream layer does not support masking yet receives such\r\n * an input mask, an exception will be raised.\r\n *\r\n * Arguments:\r\n *   - `maskValue`: Either None or mask value to skip.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape`\r\n *   (tuple of integers, does not include the samples axis)\r\n *   when using this layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Mask', namespace: 'layers'}\r\n */\n\n\nfunction masking(args) {\n  return new _core.Masking(args);\n}"},"sourceMaps":{"js":{"mappings":[{"source":"../src/exports_layers.ts","name":null,"original":{"line":11,"column":0},"generated":{"line":98,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":12,"column":0},"generated":{"line":100,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":13,"column":0},"generated":{"line":102,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":14,"column":0},"generated":{"line":104,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":15,"column":0},"generated":{"line":106,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":16,"column":0},"generated":{"line":108,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":17,"column":0},"generated":{"line":110,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":18,"column":0},"generated":{"line":112,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":114,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":20,"column":0},"generated":{"line":116,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":21,"column":0},"generated":{"line":118,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":22,"column":0},"generated":{"line":120,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":122,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":24,"column":0},"generated":{"line":124,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":25,"column":0},"generated":{"line":126,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":26,"column":0},"generated":{"line":128,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1,"column":0},"generated":{"line":130,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":28,"column":0},"generated":{"line":139,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":29,"column":0},"generated":{"line":140,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":30,"column":0},"generated":{"line":141,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":32,"column":0},"generated":{"line":142,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":33,"column":0},"generated":{"line":144,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":67,"column":6},"generated":{"line":178,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":67,"column":16},"generated":{"line":178,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":67,"column":6},"generated":{"line":178,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":67,"column":27},"generated":{"line":178,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":67,"column":6},"generated":{"line":178,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":67,"column":47},"generated":{"line":178,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":68,"column":2},"generated":{"line":179,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":68,"column":9},"generated":{"line":179,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":68,"column":13},"generated":{"line":179,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":68,"column":9},"generated":{"line":179,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":68,"column":24},"generated":{"line":179,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":68,"column":9},"generated":{"line":179,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":68,"column":2},"generated":{"line":179,"column":42}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":69,"column":1},"generated":{"line":180,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":71,"column":0},"generated":{"line":180,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":73,"column":0},"generated":{"line":182,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":97,"column":6},"generated":{"line":208,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":97,"column":16},"generated":{"line":208,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":97,"column":6},"generated":{"line":208,"column":12}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":97,"column":20},"generated":{"line":208,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":97,"column":6},"generated":{"line":208,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":97,"column":39},"generated":{"line":208,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":98,"column":2},"generated":{"line":209,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":98,"column":9},"generated":{"line":209,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":98,"column":13},"generated":{"line":209,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":98,"column":9},"generated":{"line":209,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":98,"column":17},"generated":{"line":209,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":98,"column":9},"generated":{"line":209,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":98,"column":2},"generated":{"line":209,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":99,"column":1},"generated":{"line":210,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":101,"column":0},"generated":{"line":211,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":118,"column":6},"generated":{"line":230,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":118,"column":16},"generated":{"line":230,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":118,"column":6},"generated":{"line":230,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":118,"column":21},"generated":{"line":230,"column":14}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":118,"column":6},"generated":{"line":230,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":118,"column":41},"generated":{"line":230,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":119,"column":2},"generated":{"line":231,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":231,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":119,"column":13},"generated":{"line":231,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":231,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":119,"column":18},"generated":{"line":231,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":119,"column":9},"generated":{"line":231,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":119,"column":2},"generated":{"line":231,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":120,"column":1},"generated":{"line":232,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":122,"column":0},"generated":{"line":233,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":142,"column":6},"generated":{"line":255,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":142,"column":16},"generated":{"line":255,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":142,"column":6},"generated":{"line":255,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":142,"column":26},"generated":{"line":255,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":142,"column":6},"generated":{"line":255,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":142,"column":51},"generated":{"line":255,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":143,"column":2},"generated":{"line":256,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":143,"column":9},"generated":{"line":256,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":143,"column":13},"generated":{"line":256,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":143,"column":9},"generated":{"line":256,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":143,"column":23},"generated":{"line":256,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":143,"column":9},"generated":{"line":256,"column":49}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":143,"column":2},"generated":{"line":256,"column":50}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":144,"column":1},"generated":{"line":257,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":146,"column":0},"generated":{"line":258,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":167,"column":6},"generated":{"line":281,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":167,"column":16},"generated":{"line":281,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":167,"column":6},"generated":{"line":281,"column":14}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":167,"column":22},"generated":{"line":281,"column":15}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":167,"column":6},"generated":{"line":281,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":167,"column":43},"generated":{"line":281,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":168,"column":2},"generated":{"line":282,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":168,"column":9},"generated":{"line":282,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":168,"column":13},"generated":{"line":282,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":168,"column":9},"generated":{"line":282,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":168,"column":19},"generated":{"line":282,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":168,"column":9},"generated":{"line":282,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":168,"column":2},"generated":{"line":282,"column":46}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":169,"column":1},"generated":{"line":283,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":171,"column":0},"generated":{"line":284,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":187,"column":6},"generated":{"line":302,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":187,"column":16},"generated":{"line":302,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":187,"column":6},"generated":{"line":302,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":187,"column":24},"generated":{"line":302,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":187,"column":6},"generated":{"line":302,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":187,"column":47},"generated":{"line":302,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":188,"column":2},"generated":{"line":303,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":188,"column":9},"generated":{"line":303,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":188,"column":13},"generated":{"line":303,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":188,"column":9},"generated":{"line":303,"column":42}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":188,"column":21},"generated":{"line":303,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":188,"column":9},"generated":{"line":303,"column":47}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":188,"column":2},"generated":{"line":303,"column":48}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":189,"column":1},"generated":{"line":304,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":191,"column":0},"generated":{"line":305,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":215,"column":6},"generated":{"line":331,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":215,"column":16},"generated":{"line":331,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":215,"column":6},"generated":{"line":331,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":215,"column":32},"generated":{"line":331,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":215,"column":6},"generated":{"line":331,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":215,"column":63},"generated":{"line":331,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":216,"column":2},"generated":{"line":332,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":216,"column":9},"generated":{"line":332,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":216,"column":13},"generated":{"line":332,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":216,"column":9},"generated":{"line":332,"column":50}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":216,"column":29},"generated":{"line":332,"column":51}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":216,"column":9},"generated":{"line":332,"column":55}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":216,"column":2},"generated":{"line":332,"column":56}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":217,"column":1},"generated":{"line":333,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":219,"column":0},"generated":{"line":333,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":221,"column":0},"generated":{"line":335,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":241,"column":6},"generated":{"line":357,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":241,"column":16},"generated":{"line":357,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":241,"column":6},"generated":{"line":357,"column":15}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":241,"column":23},"generated":{"line":357,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":241,"column":6},"generated":{"line":357,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":241,"column":42},"generated":{"line":357,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":242,"column":2},"generated":{"line":358,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":242,"column":9},"generated":{"line":358,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":242,"column":13},"generated":{"line":358,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":242,"column":9},"generated":{"line":358,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":242,"column":20},"generated":{"line":358,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":242,"column":9},"generated":{"line":358,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":242,"column":2},"generated":{"line":358,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":243,"column":1},"generated":{"line":359,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":245,"column":0},"generated":{"line":360,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":263,"column":6},"generated":{"line":380,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":263,"column":16},"generated":{"line":380,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":263,"column":6},"generated":{"line":380,"column":15}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":263,"column":23},"generated":{"line":380,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":263,"column":6},"generated":{"line":380,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":263,"column":42},"generated":{"line":380,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":264,"column":2},"generated":{"line":381,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":264,"column":9},"generated":{"line":381,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":264,"column":13},"generated":{"line":381,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":264,"column":9},"generated":{"line":381,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":264,"column":20},"generated":{"line":381,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":264,"column":9},"generated":{"line":381,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":264,"column":2},"generated":{"line":381,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":265,"column":1},"generated":{"line":382,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":267,"column":0},"generated":{"line":383,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":302,"column":6},"generated":{"line":420,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":302,"column":16},"generated":{"line":420,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":302,"column":6},"generated":{"line":420,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":302,"column":32},"generated":{"line":420,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":302,"column":6},"generated":{"line":420,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":302,"column":51},"generated":{"line":420,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":303,"column":2},"generated":{"line":421,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":303,"column":9},"generated":{"line":421,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":303,"column":13},"generated":{"line":421,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":303,"column":9},"generated":{"line":421,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":303,"column":29},"generated":{"line":421,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":303,"column":9},"generated":{"line":421,"column":48}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":303,"column":2},"generated":{"line":421,"column":49}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":304,"column":1},"generated":{"line":422,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":306,"column":0},"generated":{"line":423,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":324,"column":6},"generated":{"line":443,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":324,"column":16},"generated":{"line":443,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":324,"column":6},"generated":{"line":443,"column":15}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":324,"column":23},"generated":{"line":443,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":324,"column":6},"generated":{"line":443,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":324,"column":42},"generated":{"line":443,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":325,"column":2},"generated":{"line":444,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":325,"column":9},"generated":{"line":444,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":325,"column":13},"generated":{"line":444,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":325,"column":9},"generated":{"line":444,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":325,"column":20},"generated":{"line":444,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":325,"column":9},"generated":{"line":444,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":325,"column":2},"generated":{"line":444,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":326,"column":1},"generated":{"line":445,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":328,"column":0},"generated":{"line":446,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":357,"column":6},"generated":{"line":477,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":357,"column":16},"generated":{"line":477,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":357,"column":6},"generated":{"line":477,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":357,"column":32},"generated":{"line":477,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":357,"column":6},"generated":{"line":477,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":357,"column":60},"generated":{"line":477,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":358,"column":2},"generated":{"line":478,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":358,"column":9},"generated":{"line":478,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":358,"column":13},"generated":{"line":478,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":358,"column":9},"generated":{"line":478,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":358,"column":29},"generated":{"line":478,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":358,"column":9},"generated":{"line":478,"column":48}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":358,"column":2},"generated":{"line":478,"column":49}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":359,"column":1},"generated":{"line":479,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":361,"column":0},"generated":{"line":480,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":392,"column":6},"generated":{"line":513,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":392,"column":16},"generated":{"line":513,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":392,"column":6},"generated":{"line":513,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":392,"column":27},"generated":{"line":513,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":392,"column":6},"generated":{"line":513,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":392,"column":52},"generated":{"line":513,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":393,"column":2},"generated":{"line":514,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":393,"column":9},"generated":{"line":514,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":393,"column":13},"generated":{"line":514,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":393,"column":9},"generated":{"line":514,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":393,"column":24},"generated":{"line":514,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":393,"column":9},"generated":{"line":514,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":393,"column":2},"generated":{"line":514,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":394,"column":1},"generated":{"line":515,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":396,"column":0},"generated":{"line":516,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":420,"column":6},"generated":{"line":542,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":420,"column":16},"generated":{"line":542,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":420,"column":6},"generated":{"line":542,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":420,"column":29},"generated":{"line":542,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":420,"column":6},"generated":{"line":542,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":420,"column":56},"generated":{"line":542,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":421,"column":2},"generated":{"line":543,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":421,"column":9},"generated":{"line":543,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":421,"column":13},"generated":{"line":543,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":421,"column":9},"generated":{"line":543,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":421,"column":26},"generated":{"line":543,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":421,"column":9},"generated":{"line":543,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":421,"column":2},"generated":{"line":543,"column":46}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":422,"column":1},"generated":{"line":544,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":424,"column":0},"generated":{"line":544,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":426,"column":0},"generated":{"line":546,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":436,"column":6},"generated":{"line":558,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":436,"column":16},"generated":{"line":558,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":436,"column":6},"generated":{"line":558,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":436,"column":32},"generated":{"line":558,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":436,"column":6},"generated":{"line":558,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":436,"column":62},"generated":{"line":558,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":437,"column":2},"generated":{"line":559,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":437,"column":9},"generated":{"line":559,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":437,"column":13},"generated":{"line":559,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":437,"column":9},"generated":{"line":559,"column":53}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":437,"column":29},"generated":{"line":559,"column":54}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":437,"column":9},"generated":{"line":559,"column":58}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":437,"column":2},"generated":{"line":559,"column":59}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":438,"column":1},"generated":{"line":560,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":440,"column":0},"generated":{"line":560,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":442,"column":0},"generated":{"line":562,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":473,"column":6},"generated":{"line":595,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":473,"column":16},"generated":{"line":595,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":473,"column":6},"generated":{"line":595,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":473,"column":27},"generated":{"line":595,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":473,"column":6},"generated":{"line":595,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":473,"column":52},"generated":{"line":595,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":474,"column":2},"generated":{"line":596,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":474,"column":9},"generated":{"line":596,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":474,"column":13},"generated":{"line":596,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":474,"column":9},"generated":{"line":596,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":474,"column":24},"generated":{"line":596,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":474,"column":9},"generated":{"line":596,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":474,"column":2},"generated":{"line":596,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":475,"column":1},"generated":{"line":597,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":477,"column":0},"generated":{"line":598,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":510,"column":6},"generated":{"line":633,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":510,"column":16},"generated":{"line":633,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":510,"column":6},"generated":{"line":633,"column":14}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":510,"column":22},"generated":{"line":633,"column":15}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":510,"column":6},"generated":{"line":633,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":510,"column":42},"generated":{"line":633,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":511,"column":2},"generated":{"line":634,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":511,"column":9},"generated":{"line":634,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":511,"column":13},"generated":{"line":634,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":511,"column":9},"generated":{"line":634,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":511,"column":19},"generated":{"line":634,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":511,"column":9},"generated":{"line":634,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":511,"column":2},"generated":{"line":634,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":512,"column":1},"generated":{"line":635,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":514,"column":0},"generated":{"line":636,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":524,"column":6},"generated":{"line":648,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":524,"column":16},"generated":{"line":648,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":524,"column":6},"generated":{"line":648,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":524,"column":24},"generated":{"line":648,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":524,"column":6},"generated":{"line":648,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":524,"column":46},"generated":{"line":648,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":525,"column":2},"generated":{"line":649,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":525,"column":9},"generated":{"line":649,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":525,"column":13},"generated":{"line":649,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":525,"column":9},"generated":{"line":649,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":525,"column":21},"generated":{"line":649,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":525,"column":9},"generated":{"line":649,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":525,"column":2},"generated":{"line":649,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":526,"column":1},"generated":{"line":650,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":528,"column":0},"generated":{"line":651,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":560,"column":6},"generated":{"line":685,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":560,"column":16},"generated":{"line":685,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":560,"column":6},"generated":{"line":685,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":560,"column":33},"generated":{"line":685,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":560,"column":6},"generated":{"line":685,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":560,"column":66},"generated":{"line":685,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":561,"column":2},"generated":{"line":686,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":561,"column":9},"generated":{"line":686,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":561,"column":13},"generated":{"line":686,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":561,"column":9},"generated":{"line":686,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":561,"column":30},"generated":{"line":686,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":561,"column":9},"generated":{"line":686,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":561,"column":2},"generated":{"line":686,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":562,"column":1},"generated":{"line":687,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":564,"column":0},"generated":{"line":688,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":583,"column":6},"generated":{"line":709,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":583,"column":16},"generated":{"line":709,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":583,"column":6},"generated":{"line":709,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":583,"column":24},"generated":{"line":709,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":583,"column":6},"generated":{"line":709,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":583,"column":47},"generated":{"line":709,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":584,"column":2},"generated":{"line":710,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":584,"column":9},"generated":{"line":710,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":584,"column":13},"generated":{"line":710,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":584,"column":9},"generated":{"line":710,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":584,"column":21},"generated":{"line":710,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":584,"column":9},"generated":{"line":710,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":584,"column":2},"generated":{"line":710,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":585,"column":1},"generated":{"line":711,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":587,"column":0},"generated":{"line":712,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":601,"column":6},"generated":{"line":728,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":601,"column":16},"generated":{"line":728,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":601,"column":6},"generated":{"line":728,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":601,"column":29},"generated":{"line":728,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":601,"column":6},"generated":{"line":728,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":601,"column":56},"generated":{"line":728,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":602,"column":2},"generated":{"line":729,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":602,"column":9},"generated":{"line":729,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":602,"column":13},"generated":{"line":729,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":602,"column":9},"generated":{"line":729,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":602,"column":26},"generated":{"line":729,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":602,"column":9},"generated":{"line":729,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":602,"column":2},"generated":{"line":729,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":603,"column":1},"generated":{"line":730,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":605,"column":0},"generated":{"line":731,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":628,"column":6},"generated":{"line":756,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":628,"column":16},"generated":{"line":756,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":628,"column":6},"generated":{"line":756,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":628,"column":24},"generated":{"line":756,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":628,"column":6},"generated":{"line":756,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":628,"column":46},"generated":{"line":756,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":629,"column":2},"generated":{"line":757,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":629,"column":9},"generated":{"line":757,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":629,"column":13},"generated":{"line":757,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":629,"column":9},"generated":{"line":757,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":629,"column":21},"generated":{"line":757,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":629,"column":9},"generated":{"line":757,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":629,"column":2},"generated":{"line":757,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":630,"column":1},"generated":{"line":758,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":632,"column":0},"generated":{"line":759,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":660,"column":6},"generated":{"line":789,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":660,"column":16},"generated":{"line":789,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":660,"column":6},"generated":{"line":789,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":660,"column":24},"generated":{"line":789,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":660,"column":6},"generated":{"line":789,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":660,"column":46},"generated":{"line":789,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":661,"column":2},"generated":{"line":790,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":661,"column":9},"generated":{"line":790,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":661,"column":13},"generated":{"line":790,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":661,"column":9},"generated":{"line":790,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":661,"column":21},"generated":{"line":790,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":661,"column":9},"generated":{"line":790,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":661,"column":2},"generated":{"line":790,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":662,"column":1},"generated":{"line":791,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":664,"column":0},"generated":{"line":792,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":675,"column":6},"generated":{"line":805,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":675,"column":16},"generated":{"line":805,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":675,"column":6},"generated":{"line":805,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":675,"column":26},"generated":{"line":805,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":675,"column":6},"generated":{"line":805,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":675,"column":50},"generated":{"line":805,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":676,"column":2},"generated":{"line":806,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":676,"column":9},"generated":{"line":806,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":676,"column":13},"generated":{"line":806,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":676,"column":9},"generated":{"line":806,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":676,"column":23},"generated":{"line":806,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":676,"column":9},"generated":{"line":806,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":676,"column":2},"generated":{"line":806,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":677,"column":1},"generated":{"line":807,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":679,"column":0},"generated":{"line":807,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":681,"column":0},"generated":{"line":809,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":701,"column":6},"generated":{"line":831,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":701,"column":16},"generated":{"line":831,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":701,"column":6},"generated":{"line":831,"column":12}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":701,"column":20},"generated":{"line":831,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":701,"column":6},"generated":{"line":831,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":701,"column":36},"generated":{"line":831,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":702,"column":2},"generated":{"line":832,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":702,"column":9},"generated":{"line":832,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":702,"column":13},"generated":{"line":832,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":702,"column":9},"generated":{"line":832,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":702,"column":17},"generated":{"line":832,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":702,"column":9},"generated":{"line":832,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":702,"column":2},"generated":{"line":832,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":703,"column":1},"generated":{"line":833,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":705,"column":0},"generated":{"line":834,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":723,"column":6},"generated":{"line":854,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":723,"column":16},"generated":{"line":854,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":723,"column":6},"generated":{"line":854,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":723,"column":24},"generated":{"line":854,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":723,"column":6},"generated":{"line":854,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":723,"column":40},"generated":{"line":854,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":724,"column":2},"generated":{"line":855,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":724,"column":9},"generated":{"line":855,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":724,"column":13},"generated":{"line":855,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":724,"column":9},"generated":{"line":855,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":724,"column":21},"generated":{"line":855,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":724,"column":9},"generated":{"line":855,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":724,"column":2},"generated":{"line":855,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":725,"column":1},"generated":{"line":856,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":727,"column":0},"generated":{"line":857,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":747,"column":6},"generated":{"line":879,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":747,"column":16},"generated":{"line":879,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":747,"column":6},"generated":{"line":879,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":747,"column":28},"generated":{"line":879,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":747,"column":6},"generated":{"line":879,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":747,"column":55},"generated":{"line":879,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":748,"column":2},"generated":{"line":880,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":748,"column":9},"generated":{"line":880,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":748,"column":13},"generated":{"line":880,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":748,"column":9},"generated":{"line":880,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":748,"column":25},"generated":{"line":880,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":748,"column":9},"generated":{"line":880,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":748,"column":2},"generated":{"line":880,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":749,"column":1},"generated":{"line":881,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":751,"column":0},"generated":{"line":882,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":769,"column":6},"generated":{"line":902,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":769,"column":16},"generated":{"line":902,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":769,"column":6},"generated":{"line":902,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":769,"column":24},"generated":{"line":902,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":769,"column":6},"generated":{"line":902,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":769,"column":40},"generated":{"line":902,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":770,"column":2},"generated":{"line":903,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":770,"column":9},"generated":{"line":903,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":770,"column":13},"generated":{"line":903,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":770,"column":9},"generated":{"line":903,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":770,"column":21},"generated":{"line":903,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":770,"column":9},"generated":{"line":903,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":770,"column":2},"generated":{"line":903,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":771,"column":1},"generated":{"line":904,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":773,"column":0},"generated":{"line":905,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":791,"column":6},"generated":{"line":925,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":791,"column":16},"generated":{"line":925,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":791,"column":6},"generated":{"line":925,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":791,"column":24},"generated":{"line":925,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":791,"column":6},"generated":{"line":925,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":791,"column":40},"generated":{"line":925,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":792,"column":2},"generated":{"line":926,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":792,"column":9},"generated":{"line":926,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":792,"column":13},"generated":{"line":926,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":792,"column":9},"generated":{"line":926,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":792,"column":21},"generated":{"line":926,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":792,"column":9},"generated":{"line":926,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":792,"column":2},"generated":{"line":926,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":793,"column":1},"generated":{"line":927,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":795,"column":0},"generated":{"line":928,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":814,"column":6},"generated":{"line":949,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":814,"column":16},"generated":{"line":949,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":814,"column":6},"generated":{"line":949,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":814,"column":25},"generated":{"line":949,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":814,"column":6},"generated":{"line":949,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":814,"column":41},"generated":{"line":949,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":815,"column":2},"generated":{"line":950,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":815,"column":9},"generated":{"line":950,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":815,"column":13},"generated":{"line":950,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":815,"column":9},"generated":{"line":950,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":815,"column":22},"generated":{"line":950,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":815,"column":9},"generated":{"line":950,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":815,"column":2},"generated":{"line":950,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":816,"column":1},"generated":{"line":951,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":818,"column":0},"generated":{"line":952,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":840,"column":6},"generated":{"line":976,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":840,"column":16},"generated":{"line":976,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":840,"column":6},"generated":{"line":976,"column":12}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":840,"column":20},"generated":{"line":976,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":840,"column":6},"generated":{"line":976,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":840,"column":38},"generated":{"line":976,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":841,"column":2},"generated":{"line":977,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":841,"column":9},"generated":{"line":977,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":841,"column":13},"generated":{"line":977,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":841,"column":9},"generated":{"line":977,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":841,"column":17},"generated":{"line":977,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":841,"column":9},"generated":{"line":977,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":841,"column":2},"generated":{"line":977,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":842,"column":1},"generated":{"line":978,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":844,"column":0},"generated":{"line":978,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":846,"column":0},"generated":{"line":980,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":867,"column":6},"generated":{"line":1003,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":867,"column":16},"generated":{"line":1003,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":867,"column":6},"generated":{"line":1003,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":867,"column":35},"generated":{"line":1003,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":867,"column":6},"generated":{"line":1003,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":867,"column":69},"generated":{"line":1003,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":868,"column":2},"generated":{"line":1004,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":868,"column":9},"generated":{"line":1004,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":868,"column":13},"generated":{"line":1004,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":868,"column":9},"generated":{"line":1004,"column":46}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":868,"column":32},"generated":{"line":1004,"column":47}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":868,"column":9},"generated":{"line":1004,"column":51}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":868,"column":2},"generated":{"line":1004,"column":52}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":869,"column":1},"generated":{"line":1005,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":871,"column":0},"generated":{"line":1006,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":891,"column":6},"generated":{"line":1028,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":891,"column":16},"generated":{"line":1028,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":891,"column":6},"generated":{"line":1028,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":891,"column":35},"generated":{"line":1028,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":891,"column":6},"generated":{"line":1028,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":891,"column":69},"generated":{"line":1028,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":892,"column":2},"generated":{"line":1029,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":892,"column":9},"generated":{"line":1029,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":892,"column":13},"generated":{"line":1029,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":892,"column":9},"generated":{"line":1029,"column":46}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":892,"column":32},"generated":{"line":1029,"column":47}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":892,"column":9},"generated":{"line":1029,"column":51}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":892,"column":2},"generated":{"line":1029,"column":52}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":893,"column":1},"generated":{"line":1030,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":895,"column":0},"generated":{"line":1030,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":897,"column":0},"generated":{"line":1032,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":919,"column":6},"generated":{"line":1056,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":919,"column":16},"generated":{"line":1056,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":919,"column":6},"generated":{"line":1056,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":919,"column":30},"generated":{"line":1056,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":919,"column":6},"generated":{"line":1056,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":919,"column":59},"generated":{"line":1056,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":920,"column":2},"generated":{"line":1057,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":920,"column":9},"generated":{"line":1057,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":920,"column":13},"generated":{"line":1057,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":920,"column":9},"generated":{"line":1057,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":920,"column":27},"generated":{"line":1057,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":920,"column":9},"generated":{"line":1057,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":920,"column":2},"generated":{"line":1057,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":921,"column":1},"generated":{"line":1058,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":923,"column":0},"generated":{"line":1058,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":925,"column":0},"generated":{"line":1060,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":936,"column":6},"generated":{"line":1073,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":936,"column":16},"generated":{"line":1073,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":936,"column":6},"generated":{"line":1073,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":936,"column":33},"generated":{"line":1073,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":936,"column":6},"generated":{"line":1073,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":936,"column":57},"generated":{"line":1073,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":937,"column":2},"generated":{"line":1074,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":937,"column":9},"generated":{"line":1074,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":937,"column":13},"generated":{"line":1074,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":937,"column":9},"generated":{"line":1074,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":937,"column":30},"generated":{"line":1074,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":937,"column":9},"generated":{"line":1074,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":937,"column":2},"generated":{"line":1074,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":938,"column":1},"generated":{"line":1075,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":939,"column":6},"generated":{"line":1077,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":939,"column":16},"generated":{"line":1077,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":939,"column":6},"generated":{"line":1077,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":939,"column":26},"generated":{"line":1077,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":939,"column":6},"generated":{"line":1077,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":939,"column":50},"generated":{"line":1077,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":940,"column":2},"generated":{"line":1078,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":940,"column":9},"generated":{"line":1078,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":940,"column":25},"generated":{"line":1078,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":940,"column":26},"generated":{"line":1078,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":940,"column":25},"generated":{"line":1078,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":940,"column":2},"generated":{"line":1078,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":941,"column":1},"generated":{"line":1079,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":942,"column":0},"generated":{"line":1079,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":943,"column":0},"generated":{"line":1080,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":944,"column":6},"generated":{"line":1083,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":944,"column":16},"generated":{"line":1083,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":944,"column":6},"generated":{"line":1083,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":944,"column":29},"generated":{"line":1083,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":944,"column":6},"generated":{"line":1083,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":944,"column":53},"generated":{"line":1083,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":945,"column":2},"generated":{"line":1084,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":945,"column":9},"generated":{"line":1084,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":945,"column":25},"generated":{"line":1084,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":945,"column":26},"generated":{"line":1084,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":945,"column":25},"generated":{"line":1084,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":945,"column":2},"generated":{"line":1084,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":946,"column":1},"generated":{"line":1085,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":948,"column":0},"generated":{"line":1086,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":971,"column":6},"generated":{"line":1111,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":971,"column":16},"generated":{"line":1111,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":971,"column":6},"generated":{"line":1111,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":971,"column":33},"generated":{"line":1111,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":971,"column":6},"generated":{"line":1111,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":971,"column":57},"generated":{"line":1111,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":972,"column":2},"generated":{"line":1112,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":972,"column":9},"generated":{"line":1112,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":972,"column":13},"generated":{"line":1112,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":972,"column":9},"generated":{"line":1112,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":972,"column":30},"generated":{"line":1112,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":972,"column":9},"generated":{"line":1112,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":972,"column":2},"generated":{"line":1112,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":973,"column":1},"generated":{"line":1113,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":974,"column":6},"generated":{"line":1115,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":974,"column":16},"generated":{"line":1115,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":974,"column":6},"generated":{"line":1115,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":974,"column":26},"generated":{"line":1115,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":974,"column":6},"generated":{"line":1115,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":974,"column":50},"generated":{"line":1115,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":975,"column":2},"generated":{"line":1116,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":975,"column":9},"generated":{"line":1116,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":975,"column":25},"generated":{"line":1116,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":975,"column":26},"generated":{"line":1116,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":975,"column":25},"generated":{"line":1116,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":975,"column":2},"generated":{"line":1116,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":976,"column":1},"generated":{"line":1117,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":977,"column":0},"generated":{"line":1117,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":978,"column":0},"generated":{"line":1118,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":979,"column":6},"generated":{"line":1121,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":979,"column":16},"generated":{"line":1121,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":979,"column":6},"generated":{"line":1121,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":979,"column":29},"generated":{"line":1121,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":979,"column":6},"generated":{"line":1121,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":979,"column":53},"generated":{"line":1121,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":980,"column":2},"generated":{"line":1122,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":980,"column":9},"generated":{"line":1122,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":980,"column":25},"generated":{"line":1122,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":980,"column":26},"generated":{"line":1122,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":980,"column":25},"generated":{"line":1122,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":980,"column":2},"generated":{"line":1122,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":981,"column":1},"generated":{"line":1123,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":983,"column":0},"generated":{"line":1124,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1004,"column":6},"generated":{"line":1147,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1004,"column":16},"generated":{"line":1147,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1004,"column":6},"generated":{"line":1147,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1004,"column":33},"generated":{"line":1147,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1004,"column":6},"generated":{"line":1147,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1004,"column":57},"generated":{"line":1147,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1005,"column":2},"generated":{"line":1148,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1005,"column":9},"generated":{"line":1148,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1005,"column":13},"generated":{"line":1148,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1005,"column":9},"generated":{"line":1148,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1005,"column":30},"generated":{"line":1148,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1005,"column":9},"generated":{"line":1148,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1005,"column":2},"generated":{"line":1148,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1006,"column":1},"generated":{"line":1149,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1007,"column":6},"generated":{"line":1151,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1007,"column":16},"generated":{"line":1151,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1007,"column":6},"generated":{"line":1151,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1007,"column":26},"generated":{"line":1151,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1007,"column":6},"generated":{"line":1151,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1007,"column":50},"generated":{"line":1151,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1008,"column":2},"generated":{"line":1152,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1008,"column":9},"generated":{"line":1152,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1008,"column":25},"generated":{"line":1152,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1008,"column":26},"generated":{"line":1152,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1008,"column":25},"generated":{"line":1152,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1008,"column":2},"generated":{"line":1152,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1009,"column":1},"generated":{"line":1153,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1010,"column":0},"generated":{"line":1153,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1011,"column":0},"generated":{"line":1154,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1012,"column":6},"generated":{"line":1157,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1012,"column":16},"generated":{"line":1157,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1012,"column":6},"generated":{"line":1157,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1012,"column":29},"generated":{"line":1157,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1012,"column":6},"generated":{"line":1157,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1012,"column":53},"generated":{"line":1157,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1013,"column":2},"generated":{"line":1158,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1013,"column":9},"generated":{"line":1158,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1013,"column":25},"generated":{"line":1158,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1013,"column":26},"generated":{"line":1158,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1013,"column":25},"generated":{"line":1158,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1013,"column":2},"generated":{"line":1158,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1014,"column":1},"generated":{"line":1159,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1016,"column":0},"generated":{"line":1160,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1025,"column":6},"generated":{"line":1171,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1025,"column":16},"generated":{"line":1171,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1025,"column":6},"generated":{"line":1171,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1025,"column":39},"generated":{"line":1171,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1025,"column":6},"generated":{"line":1171,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1025,"column":55},"generated":{"line":1171,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1026,"column":2},"generated":{"line":1172,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1026,"column":9},"generated":{"line":1172,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1026,"column":13},"generated":{"line":1172,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1026,"column":9},"generated":{"line":1172,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1026,"column":36},"generated":{"line":1172,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1026,"column":9},"generated":{"line":1172,"column":49}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1026,"column":2},"generated":{"line":1172,"column":50}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1027,"column":1},"generated":{"line":1173,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1029,"column":0},"generated":{"line":1174,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1043,"column":6},"generated":{"line":1190,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1043,"column":16},"generated":{"line":1190,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1043,"column":6},"generated":{"line":1190,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1043,"column":39},"generated":{"line":1190,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1043,"column":6},"generated":{"line":1190,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1043,"column":69},"generated":{"line":1190,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1044,"column":2},"generated":{"line":1191,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1044,"column":9},"generated":{"line":1191,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1044,"column":13},"generated":{"line":1191,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1044,"column":9},"generated":{"line":1191,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1044,"column":36},"generated":{"line":1191,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1044,"column":9},"generated":{"line":1191,"column":49}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1044,"column":2},"generated":{"line":1191,"column":50}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1045,"column":1},"generated":{"line":1192,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1047,"column":0},"generated":{"line":1193,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1056,"column":6},"generated":{"line":1204,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1056,"column":16},"generated":{"line":1204,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1056,"column":6},"generated":{"line":1204,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1056,"column":35},"generated":{"line":1204,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1056,"column":6},"generated":{"line":1204,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1056,"column":51},"generated":{"line":1204,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1057,"column":2},"generated":{"line":1205,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1057,"column":9},"generated":{"line":1205,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1057,"column":13},"generated":{"line":1205,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1057,"column":9},"generated":{"line":1205,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1057,"column":32},"generated":{"line":1205,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1057,"column":9},"generated":{"line":1205,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1057,"column":2},"generated":{"line":1205,"column":46}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1058,"column":1},"generated":{"line":1206,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1060,"column":0},"generated":{"line":1207,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1074,"column":6},"generated":{"line":1223,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1074,"column":16},"generated":{"line":1223,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1074,"column":6},"generated":{"line":1223,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1074,"column":35},"generated":{"line":1223,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1074,"column":6},"generated":{"line":1223,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1074,"column":65},"generated":{"line":1223,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1075,"column":2},"generated":{"line":1224,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1075,"column":9},"generated":{"line":1224,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1075,"column":13},"generated":{"line":1224,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1075,"column":9},"generated":{"line":1224,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1075,"column":32},"generated":{"line":1224,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1075,"column":9},"generated":{"line":1224,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1075,"column":2},"generated":{"line":1224,"column":46}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1076,"column":1},"generated":{"line":1225,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1078,"column":0},"generated":{"line":1226,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1087,"column":6},"generated":{"line":1237,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1087,"column":16},"generated":{"line":1237,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1087,"column":6},"generated":{"line":1237,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1087,"column":29},"generated":{"line":1237,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1087,"column":6},"generated":{"line":1237,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1087,"column":53},"generated":{"line":1237,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1088,"column":2},"generated":{"line":1238,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1088,"column":9},"generated":{"line":1238,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1088,"column":13},"generated":{"line":1238,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1088,"column":9},"generated":{"line":1238,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1088,"column":26},"generated":{"line":1238,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1088,"column":9},"generated":{"line":1238,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1088,"column":2},"generated":{"line":1238,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1089,"column":1},"generated":{"line":1239,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1091,"column":0},"generated":{"line":1240,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1112,"column":6},"generated":{"line":1263,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1112,"column":16},"generated":{"line":1263,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1112,"column":6},"generated":{"line":1263,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1112,"column":29},"generated":{"line":1263,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1112,"column":6},"generated":{"line":1263,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1112,"column":53},"generated":{"line":1263,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1113,"column":2},"generated":{"line":1264,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1113,"column":9},"generated":{"line":1264,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1113,"column":13},"generated":{"line":1264,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1113,"column":9},"generated":{"line":1264,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1113,"column":26},"generated":{"line":1264,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1113,"column":9},"generated":{"line":1264,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1113,"column":2},"generated":{"line":1264,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1114,"column":1},"generated":{"line":1265,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1116,"column":0},"generated":{"line":1266,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1137,"column":6},"generated":{"line":1289,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1137,"column":16},"generated":{"line":1289,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1137,"column":6},"generated":{"line":1289,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1137,"column":29},"generated":{"line":1289,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1137,"column":6},"generated":{"line":1289,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1137,"column":53},"generated":{"line":1289,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1138,"column":2},"generated":{"line":1290,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1138,"column":9},"generated":{"line":1290,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1138,"column":13},"generated":{"line":1290,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1138,"column":9},"generated":{"line":1290,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1138,"column":26},"generated":{"line":1290,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1138,"column":9},"generated":{"line":1290,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1138,"column":2},"generated":{"line":1290,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1139,"column":1},"generated":{"line":1291,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1141,"column":0},"generated":{"line":1291,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1143,"column":0},"generated":{"line":1293,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1166,"column":6},"generated":{"line":1318,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1166,"column":16},"generated":{"line":1318,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1166,"column":6},"generated":{"line":1318,"column":12}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1166,"column":20},"generated":{"line":1318,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1166,"column":6},"generated":{"line":1318,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1166,"column":38},"generated":{"line":1318,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1167,"column":2},"generated":{"line":1319,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1167,"column":9},"generated":{"line":1319,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1167,"column":13},"generated":{"line":1319,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1167,"column":9},"generated":{"line":1319,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1167,"column":17},"generated":{"line":1319,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1167,"column":9},"generated":{"line":1319,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1167,"column":2},"generated":{"line":1319,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1168,"column":1},"generated":{"line":1320,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1170,"column":0},"generated":{"line":1321,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1215,"column":6},"generated":{"line":1368,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1215,"column":16},"generated":{"line":1368,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1215,"column":6},"generated":{"line":1368,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1215,"column":24},"generated":{"line":1368,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1215,"column":6},"generated":{"line":1368,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1215,"column":46},"generated":{"line":1368,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1216,"column":2},"generated":{"line":1369,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1216,"column":9},"generated":{"line":1369,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1216,"column":13},"generated":{"line":1369,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1216,"column":9},"generated":{"line":1369,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1216,"column":21},"generated":{"line":1369,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1216,"column":9},"generated":{"line":1369,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1216,"column":2},"generated":{"line":1369,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1217,"column":1},"generated":{"line":1370,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1219,"column":0},"generated":{"line":1371,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1242,"column":6},"generated":{"line":1396,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1242,"column":16},"generated":{"line":1396,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1242,"column":6},"generated":{"line":1396,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1242,"column":21},"generated":{"line":1396,"column":14}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1242,"column":6},"generated":{"line":1396,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1242,"column":40},"generated":{"line":1396,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1243,"column":2},"generated":{"line":1397,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1243,"column":9},"generated":{"line":1397,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1243,"column":13},"generated":{"line":1397,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1243,"column":9},"generated":{"line":1397,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1243,"column":18},"generated":{"line":1397,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1243,"column":9},"generated":{"line":1397,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1243,"column":2},"generated":{"line":1397,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1244,"column":1},"generated":{"line":1398,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1246,"column":0},"generated":{"line":1399,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1291,"column":6},"generated":{"line":1446,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1291,"column":16},"generated":{"line":1446,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1291,"column":6},"generated":{"line":1446,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1291,"column":25},"generated":{"line":1446,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1291,"column":6},"generated":{"line":1446,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1291,"column":48},"generated":{"line":1446,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1292,"column":2},"generated":{"line":1447,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1292,"column":9},"generated":{"line":1447,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1292,"column":13},"generated":{"line":1447,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1292,"column":9},"generated":{"line":1447,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1292,"column":22},"generated":{"line":1447,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1292,"column":9},"generated":{"line":1447,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1292,"column":2},"generated":{"line":1447,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1293,"column":1},"generated":{"line":1448,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1295,"column":0},"generated":{"line":1449,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1319,"column":6},"generated":{"line":1475,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1319,"column":16},"generated":{"line":1475,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1319,"column":6},"generated":{"line":1475,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1319,"column":26},"generated":{"line":1475,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1319,"column":6},"generated":{"line":1475,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1319,"column":50},"generated":{"line":1475,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1320,"column":2},"generated":{"line":1476,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1320,"column":9},"generated":{"line":1476,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1320,"column":13},"generated":{"line":1476,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1320,"column":9},"generated":{"line":1476,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1320,"column":23},"generated":{"line":1476,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1320,"column":9},"generated":{"line":1476,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1320,"column":2},"generated":{"line":1476,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1321,"column":1},"generated":{"line":1477,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1323,"column":0},"generated":{"line":1478,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1368,"column":6},"generated":{"line":1525,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1368,"column":16},"generated":{"line":1525,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1368,"column":6},"generated":{"line":1525,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1368,"column":30},"generated":{"line":1525,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1368,"column":6},"generated":{"line":1525,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1368,"column":58},"generated":{"line":1525,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1369,"column":2},"generated":{"line":1526,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1369,"column":9},"generated":{"line":1526,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1369,"column":13},"generated":{"line":1526,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1369,"column":9},"generated":{"line":1526,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1369,"column":27},"generated":{"line":1526,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1369,"column":9},"generated":{"line":1526,"column":42}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1369,"column":2},"generated":{"line":1526,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1370,"column":1},"generated":{"line":1527,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1372,"column":0},"generated":{"line":1528,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1398,"column":0},"generated":{"line":1555,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1399,"column":6},"generated":{"line":1558,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1399,"column":16},"generated":{"line":1558,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1399,"column":6},"generated":{"line":1558,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1399,"column":27},"generated":{"line":1558,"column":20}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1399,"column":6},"generated":{"line":1558,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1399,"column":47},"generated":{"line":1558,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1400,"column":2},"generated":{"line":1559,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1400,"column":9},"generated":{"line":1559,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1400,"column":13},"generated":{"line":1559,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1400,"column":9},"generated":{"line":1559,"column":48}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1400,"column":24},"generated":{"line":1559,"column":49}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1400,"column":9},"generated":{"line":1559,"column":53}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1400,"column":2},"generated":{"line":1559,"column":54}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1401,"column":1},"generated":{"line":1560,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1403,"column":0},"generated":{"line":1561,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1435,"column":0},"generated":{"line":1594,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1436,"column":6},"generated":{"line":1597,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1436,"column":16},"generated":{"line":1597,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1436,"column":6},"generated":{"line":1597,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1436,"column":31},"generated":{"line":1597,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1436,"column":6},"generated":{"line":1597,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1436,"column":55},"generated":{"line":1597,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1437,"column":2},"generated":{"line":1598,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1437,"column":9},"generated":{"line":1598,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1437,"column":13},"generated":{"line":1598,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1437,"column":9},"generated":{"line":1598,"column":52}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1437,"column":28},"generated":{"line":1598,"column":53}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1437,"column":9},"generated":{"line":1598,"column":57}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1437,"column":2},"generated":{"line":1598,"column":58}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1438,"column":1},"generated":{"line":1599,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1440,"column":0},"generated":{"line":1600,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1500,"column":6},"generated":{"line":1662,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1500,"column":16},"generated":{"line":1662,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1500,"column":6},"generated":{"line":1662,"column":12}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1500,"column":20},"generated":{"line":1662,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1500,"column":6},"generated":{"line":1662,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1500,"column":38},"generated":{"line":1662,"column":19}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1501,"column":2},"generated":{"line":1663,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1501,"column":9},"generated":{"line":1663,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1501,"column":13},"generated":{"line":1663,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1501,"column":9},"generated":{"line":1663,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1501,"column":17},"generated":{"line":1663,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1501,"column":9},"generated":{"line":1663,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1501,"column":2},"generated":{"line":1663,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1502,"column":1},"generated":{"line":1664,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1504,"column":0},"generated":{"line":1665,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1511,"column":6},"generated":{"line":1674,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1511,"column":16},"generated":{"line":1674,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1511,"column":6},"generated":{"line":1674,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1511,"column":32},"generated":{"line":1674,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1511,"column":6},"generated":{"line":1674,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1511,"column":57},"generated":{"line":1674,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1512,"column":2},"generated":{"line":1675,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1512,"column":9},"generated":{"line":1675,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1512,"column":13},"generated":{"line":1675,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1512,"column":9},"generated":{"line":1675,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1512,"column":29},"generated":{"line":1675,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1512,"column":9},"generated":{"line":1675,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1512,"column":2},"generated":{"line":1675,"column":45}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1513,"column":1},"generated":{"line":1676,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1515,"column":0},"generated":{"line":1676,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1517,"column":0},"generated":{"line":1678,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1518,"column":6},"generated":{"line":1681,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1518,"column":16},"generated":{"line":1681,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1518,"column":6},"generated":{"line":1681,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1518,"column":30},"generated":{"line":1681,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1518,"column":6},"generated":{"line":1681,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1518,"column":58},"generated":{"line":1681,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1519,"column":2},"generated":{"line":1682,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1519,"column":9},"generated":{"line":1682,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1519,"column":13},"generated":{"line":1682,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1519,"column":9},"generated":{"line":1682,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1519,"column":27},"generated":{"line":1682,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1519,"column":9},"generated":{"line":1682,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1519,"column":2},"generated":{"line":1682,"column":42}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1520,"column":1},"generated":{"line":1683,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1522,"column":0},"generated":{"line":1684,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1568,"column":6},"generated":{"line":1732,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1568,"column":16},"generated":{"line":1732,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1568,"column":6},"generated":{"line":1732,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1568,"column":32},"generated":{"line":1732,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1568,"column":6},"generated":{"line":1732,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1568,"column":54},"generated":{"line":1732,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1569,"column":2},"generated":{"line":1733,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1569,"column":9},"generated":{"line":1733,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1569,"column":13},"generated":{"line":1733,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1569,"column":9},"generated":{"line":1733,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1569,"column":29},"generated":{"line":1733,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1569,"column":9},"generated":{"line":1733,"column":43}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1569,"column":2},"generated":{"line":1733,"column":44}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1570,"column":1},"generated":{"line":1734,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1572,"column":0},"generated":{"line":1734,"column":2}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1573,"column":7},"generated":{"line":1737,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1573,"column":13},"generated":{"line":1737,"column":6}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1573,"column":28},"generated":{"line":1737,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1573,"column":31},"generated":{"line":1737,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1573,"column":7},"generated":{"line":1737,"column":42}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1574,"column":7},"generated":{"line":1739,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1574,"column":13},"generated":{"line":1739,"column":6}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1574,"column":28},"generated":{"line":1739,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1574,"column":31},"generated":{"line":1739,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1574,"column":7},"generated":{"line":1739,"column":42}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1575,"column":7},"generated":{"line":1741,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1575,"column":13},"generated":{"line":1741,"column":6}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1575,"column":22},"generated":{"line":1741,"column":15}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1575,"column":25},"generated":{"line":1741,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1575,"column":7},"generated":{"line":1741,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1576,"column":7},"generated":{"line":1743,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1576,"column":13},"generated":{"line":1743,"column":6}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1576,"column":22},"generated":{"line":1743,"column":15}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1576,"column":25},"generated":{"line":1743,"column":18}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1576,"column":7},"generated":{"line":1743,"column":30}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1580,"column":0},"generated":{"line":1746,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1603,"column":6},"generated":{"line":1769,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1603,"column":16},"generated":{"line":1769,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1603,"column":6},"generated":{"line":1769,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1603,"column":30},"generated":{"line":1769,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1603,"column":6},"generated":{"line":1769,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1603,"column":53},"generated":{"line":1769,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1604,"column":2},"generated":{"line":1770,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1604,"column":9},"generated":{"line":1770,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1604,"column":13},"generated":{"line":1770,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1604,"column":9},"generated":{"line":1770,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1604,"column":27},"generated":{"line":1770,"column":34}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1604,"column":9},"generated":{"line":1770,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1604,"column":2},"generated":{"line":1770,"column":39}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1605,"column":1},"generated":{"line":1771,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1607,"column":0},"generated":{"line":1772,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1631,"column":6},"generated":{"line":1798,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1631,"column":16},"generated":{"line":1798,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1631,"column":6},"generated":{"line":1798,"column":24}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1631,"column":32},"generated":{"line":1798,"column":25}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1631,"column":6},"generated":{"line":1798,"column":29}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1631,"column":57},"generated":{"line":1798,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1632,"column":2},"generated":{"line":1799,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1632,"column":9},"generated":{"line":1799,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1632,"column":13},"generated":{"line":1799,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1632,"column":9},"generated":{"line":1799,"column":35}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1632,"column":29},"generated":{"line":1799,"column":36}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1632,"column":9},"generated":{"line":1799,"column":40}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1632,"column":2},"generated":{"line":1799,"column":41}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1633,"column":1},"generated":{"line":1800,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1635,"column":0},"generated":{"line":1801,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1666,"column":6},"generated":{"line":1834,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1666,"column":16},"generated":{"line":1834,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1666,"column":6},"generated":{"line":1834,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1666,"column":29},"generated":{"line":1834,"column":22}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1666,"column":6},"generated":{"line":1834,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1666,"column":51},"generated":{"line":1834,"column":28}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1667,"column":2},"generated":{"line":1835,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1667,"column":9},"generated":{"line":1835,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1667,"column":13},"generated":{"line":1835,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1667,"column":9},"generated":{"line":1835,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1667,"column":26},"generated":{"line":1835,"column":33}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1667,"column":9},"generated":{"line":1835,"column":37}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1667,"column":2},"generated":{"line":1835,"column":38}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1668,"column":1},"generated":{"line":1836,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1670,"column":0},"generated":{"line":1837,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1693,"column":6},"generated":{"line":1862,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1693,"column":16},"generated":{"line":1862,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1693,"column":6},"generated":{"line":1862,"column":16}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1693,"column":24},"generated":{"line":1862,"column":17}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1693,"column":6},"generated":{"line":1862,"column":21}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1693,"column":42},"generated":{"line":1862,"column":23}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1694,"column":2},"generated":{"line":1863,"column":0}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1694,"column":9},"generated":{"line":1863,"column":9}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1694,"column":13},"generated":{"line":1863,"column":13}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1694,"column":9},"generated":{"line":1863,"column":26}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1694,"column":21},"generated":{"line":1863,"column":27}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1694,"column":9},"generated":{"line":1863,"column":31}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1694,"column":2},"generated":{"line":1863,"column":32}},{"source":"../src/exports_layers.ts","name":null,"original":{"line":1695,"column":1},"generated":{"line":1864,"column":0}}],"sources":{"../src/exports_layers.ts":"/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\r\n\r\nimport {InputLayer, InputLayerArgs} from './engine/input_layer';\r\nimport {Layer, LayerArgs} from './engine/topology';\r\nimport {input} from './exports';\r\nimport {ELU, ELULayerArgs, LeakyReLU, LeakyReLULayerArgs, PReLU, PReLULayerArgs, ReLU, ReLULayerArgs, Softmax, SoftmaxLayerArgs, ThresholdedReLU, ThresholdedReLULayerArgs} from './layers/advanced_activations';\r\nimport {Conv1D, Conv2D, Conv2DTranspose, Conv3D, ConvLayerArgs, Cropping2D, Cropping2DLayerArgs, SeparableConv2D, SeparableConvLayerArgs, UpSampling2D, UpSampling2DLayerArgs} from './layers/convolutional';\r\nimport {DepthwiseConv2D, DepthwiseConv2DLayerArgs} from './layers/convolutional_depthwise';\r\nimport {ConvLSTM2D, ConvLSTM2DArgs, ConvLSTM2DCell, ConvLSTM2DCellArgs} from './layers/convolutional_recurrent';\r\nimport {Activation, ActivationLayerArgs, Dense, DenseLayerArgs, Dropout, DropoutLayerArgs, Flatten, FlattenLayerArgs, Masking, MaskingArgs, Permute, PermuteLayerArgs, RepeatVector, RepeatVectorLayerArgs, Reshape, ReshapeLayerArgs, SpatialDropout1D, SpatialDropout1DLayerConfig} from './layers/core';\r\nimport {Embedding, EmbeddingLayerArgs} from './layers/embeddings';\r\nimport {Add, Average, Concatenate, ConcatenateLayerArgs, Dot, DotLayerArgs, Maximum, Minimum, Multiply} from './layers/merge';\r\nimport {AlphaDropout, AlphaDropoutArgs, GaussianDropout, GaussianDropoutArgs, GaussianNoise, GaussianNoiseArgs} from './layers/noise';\r\nimport {BatchNormalization, BatchNormalizationLayerArgs, LayerNormalization, LayerNormalizationLayerArgs} from './layers/normalization';\r\nimport {ZeroPadding2D, ZeroPadding2DLayerArgs} from './layers/padding';\r\nimport {AveragePooling1D, AveragePooling2D, AveragePooling3D, GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D, GlobalPooling2DLayerArgs, MaxPooling1D, MaxPooling2D, MaxPooling3D, Pooling1DLayerArgs, Pooling2DLayerArgs, Pooling3DLayerArgs} from './layers/pooling';\r\nimport {GRU, GRUCell, GRUCellLayerArgs, GRULayerArgs, LSTM, LSTMCell, LSTMCellLayerArgs, LSTMLayerArgs, RNN, RNNCell, RNNLayerArgs, SimpleRNN, SimpleRNNCell, SimpleRNNCellLayerArgs, SimpleRNNLayerArgs, StackedRNNCells, StackedRNNCellsArgs} from './layers/recurrent';\r\nimport {Bidirectional, BidirectionalLayerArgs, TimeDistributed, WrapperLayerArgs} from './layers/wrappers';\r\n\r\n// TODO(cais): Add doc string to all the public static functions in this\r\n//   class; include exectuable JavaScript code snippets where applicable\r\n//   (b/74074458).\r\n\r\n// Input Layer.\r\n/**\r\n * An input layer is an entry point into a `tf.LayersModel`.\r\n *\r\n * `InputLayer` is generated automatically for `tf.Sequential`` models by\r\n * specifying the `inputshape` or `batchInputShape` for the first layer.  It\r\n * should not be specified explicitly. However, it can be useful sometimes,\r\n * e.g., when constructing a sequential model from a subset of another\r\n * sequential model's layers. Like the code snippet below shows.\r\n *\r\n * ```js\r\n * // Define a model which simply adds two inputs.\r\n * const model1 = tf.sequential();\r\n * model1.add(tf.layers.dense({inputShape: [4], units: 3, activation: 'relu'}));\r\n * model1.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));\r\n * model1.summary();\r\n * model1.predict(tf.zeros([1, 4])).print();\r\n *\r\n * // Construct another model, reusing the second layer of `model1` while\r\n * // not using the first layer of `model1`. Note that you cannot add the second\r\n * // layer of `model` directly as the first layer of the new sequential model,\r\n * // because doing so will lead to an error related to the fact that the layer\r\n * // is not an input layer. Instead, you need to create an `inputLayer` and add\r\n * // it to the new sequential model before adding the reused layer.\r\n * const model2 = tf.sequential();\r\n * // Use an inputShape that matches the input shape of `model1`'s second\r\n * // layer.\r\n * model2.add(tf.layers.inputLayer({inputShape: [3]}));\r\n * model2.add(model1.layers[1]);\r\n * model2.summary();\r\n * model2.predict(tf.zeros([1, 3])).print();\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Inputs', namespace: 'layers'}\r\n */\r\nexport function inputLayer(args: InputLayerArgs) {\r\n  return new InputLayer(args);\r\n}\r\n\r\n// Advanced Activation Layers.\r\n\r\n/**\r\n * Exponetial Linear Unit (ELU).\r\n *\r\n * It follows:\r\n * `f(x) =  alpha * (exp(x) - 1.) for x < 0`,\r\n * `f(x) = x for x >= 0`.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * References:\r\n *   - [Fast and Accurate Deep Network Learning by Exponential Linear Units\r\n * (ELUs)](https://arxiv.org/abs/1511.07289v1)\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\r\nexport function elu(args?: ELULayerArgs) {\r\n  return new ELU(args);\r\n}\r\n\r\n/**\r\n * Rectified Linear Unit activation function.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the config field `inputShape` (Array of integers, does\r\n *   not include the sample axis) when using this layer as the first layer\r\n *   in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\r\nexport function reLU(args?: ReLULayerArgs) {\r\n  return new ReLU(args);\r\n}\r\n\r\n/**\r\n * Leaky version of a rectified linear unit.\r\n *\r\n * It allows a small gradient when the unit is not active:\r\n * `f(x) = alpha * x for x < 0.`\r\n * `f(x) = x for x >= 0.`\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\r\nexport function leakyReLU(args?: LeakyReLULayerArgs) {\r\n  return new LeakyReLU(args);\r\n}\r\n\r\n/**\r\n * Parameterized version of a leaky rectified linear unit.\r\n *\r\n * It follows\r\n * `f(x) = alpha * x for x < 0.`\r\n * `f(x) = x for x >= 0.`\r\n * wherein `alpha` is a trainable weight.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\r\nexport function prelu(args?: PReLULayerArgs) {\r\n  return new PReLU(args);\r\n}\r\n\r\n/**\r\n * Softmax activation layer.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\r\nexport function softmax(args?: SoftmaxLayerArgs) {\r\n  return new Softmax(args);\r\n}\r\n\r\n/**\r\n * Thresholded Rectified Linear Unit.\r\n *\r\n * It follows:\r\n * `f(x) = x for x > theta`,\r\n * `f(x) = 0 otherwise`.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as the input.\r\n *\r\n * References:\r\n *   - [Zero-Bias Autoencoders and the Benefits of Co-Adapting\r\n * Features](http://arxiv.org/abs/1402.3337)\r\n *\r\n * @doc {\r\n *   heading: 'Layers',\r\n *   subheading: 'Advanced Activation',\r\n *   namespace: 'layers'\r\n * }\r\n */\r\nexport function thresholdedReLU(args?: ThresholdedReLULayerArgs) {\r\n  return new ThresholdedReLU(args);\r\n}\r\n\r\n// Convolutional Layers.\r\n\r\n/**\r\n * 1D convolution layer (e.g., temporal convolution).\r\n *\r\n * This layer creates a convolution kernel that is convolved\r\n * with the layer input over a single spatial (or temporal) dimension\r\n * to produce a tensor of outputs.\r\n *\r\n * If `use_bias` is True, a bias vector is created and added to the outputs.\r\n *\r\n * If `activation` is not `null`, it is applied to the outputs as well.\r\n *\r\n * When using this layer as the first layer in a model, provide an\r\n * `inputShape` argument `Array` or `null`.\r\n *\r\n * For example, `inputShape` would be:\r\n * - `[10, 128]` for sequences of 10 vectors of 128-dimensional vectors\r\n * - `[null, 128]` for variable-length sequences of 128-dimensional vectors.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional',  namespace: 'layers'}\r\n */\r\nexport function conv1d(args: ConvLayerArgs) {\r\n  return new Conv1D(args);\r\n}\r\n\r\n/**\r\n * 2D convolution layer (e.g. spatial convolution over images).\r\n *\r\n * This layer creates a convolution kernel that is convolved\r\n * with the layer input to produce a tensor of outputs.\r\n *\r\n * If `useBias` is True, a bias vector is created and added to the outputs.\r\n *\r\n * If `activation` is not `null`, it is applied to the outputs as well.\r\n *\r\n * When using this layer as the first layer in a model,\r\n * provide the keyword argument `inputShape`\r\n * (Array of integers, does not include the sample axis),\r\n * e.g. `inputShape=[128, 128, 3]` for 128x128 RGB pictures\r\n * in `dataFormat='channelsLast'`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\r\nexport function conv2d(args: ConvLayerArgs) {\r\n  return new Conv2D(args);\r\n}\r\n\r\n/**\r\n * Transposed convolutional layer (sometimes called Deconvolution).\r\n *\r\n * The need for transposed convolutions generally arises\r\n * from the desire to use a transformation going in the opposite direction of\r\n * a normal convolution, i.e., from something that has the shape of the output\r\n * of some convolution to something that has the shape of its input while\r\n * maintaining a connectivity pattern that is compatible with said\r\n * convolution.\r\n *\r\n * When using this layer as the first layer in a model, provide the\r\n * configuration `inputShape` (`Array` of integers, does not include the\r\n * sample axis), e.g., `inputShape: [128, 128, 3]` for 128x128 RGB pictures in\r\n * `dataFormat: 'channelsLast'`.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *   `[batch, channels, rows, cols]` if `dataFormat` is `'channelsFirst'`.\r\n *   or 4D tensor with shape\r\n *   `[batch, rows, cols, channels]` if `dataFormat` is `'channelsLast`.\r\n *\r\n * Output shape:\r\n *   4D tensor with shape:\r\n *   `[batch, filters, newRows, newCols]` if `dataFormat` is\r\n * `'channelsFirst'`. or 4D tensor with shape:\r\n *   `[batch, newRows, newCols, filters]` if `dataFormat` is `'channelsLast'`.\r\n *\r\n * References:\r\n *   - [A guide to convolution arithmetic for deep\r\n * learning](https://arxiv.org/abs/1603.07285v1)\r\n *   - [Deconvolutional\r\n * Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\r\nexport function conv2dTranspose(args: ConvLayerArgs) {\r\n  return new Conv2DTranspose(args);\r\n}\r\n\r\n/**\r\n * 3D convolution layer (e.g. spatial convolution over volumes).\r\n *\r\n * This layer creates a convolution kernel that is convolved\r\n * with the layer input to produce a tensor of outputs.\r\n *\r\n * If `useBias` is True, a bias vector is created and added to the outputs.\r\n *\r\n * If `activation` is not `null`, it is applied to the outputs as well.\r\n *\r\n * When using this layer as the first layer in a model,\r\n * provide the keyword argument `inputShape`\r\n * (Array of integers, does not include the sample axis),\r\n * e.g. `inputShape=[128, 128, 128, 1]` for 128x128x128 grayscale volumes\r\n * in `dataFormat='channelsLast'`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\r\nexport function conv3d(args: ConvLayerArgs) {\r\n  return new Conv3D(args);\r\n}\r\n\r\n/**\r\n * Depthwise separable 2D convolution.\r\n *\r\n * Separable convolution consists of first performing\r\n * a depthwise spatial convolution\r\n * (which acts on each input channel separately)\r\n * followed by a pointwise convolution which mixes together the resulting\r\n * output channels. The `depthMultiplier` argument controls how many\r\n * output channels are generated per input channel in the depthwise step.\r\n *\r\n * Intuitively, separable convolutions can be understood as\r\n * a way to factorize a convolution kernel into two smaller kernels,\r\n * or as an extreme version of an Inception block.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *     `[batch, channels, rows, cols]` if data_format='channelsFirst'\r\n *   or 4D tensor with shape:\r\n *     `[batch, rows, cols, channels]` if data_format='channelsLast'.\r\n *\r\n * Output shape:\r\n *   4D tensor with shape:\r\n *     `[batch, filters, newRows, newCols]` if data_format='channelsFirst'\r\n *   or 4D tensor with shape:\r\n *     `[batch, newRows, newCols, filters]` if data_format='channelsLast'.\r\n *     `rows` and `cols` values might have changed due to padding.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\r\nexport function separableConv2d(args: SeparableConvLayerArgs) {\r\n  return new SeparableConv2D(args);\r\n}\r\n\r\n/**\r\n * Cropping layer for 2D input (e.g., image).\r\n *\r\n * This layer can crop an input\r\n * at the top, bottom, left and right side of an image tensor.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, rows, cols, channels]`\r\n *   - If `data_format` is `\"channels_first\"`:\r\n *     `[batch, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   4D with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, croppedRows, croppedCols, channels]`\r\n *    - If `dataFormat` is `\"channelsFirst\"`:\r\n *     `[batch, channels, croppedRows, croppedCols]`.\r\n *\r\n * Examples\r\n * ```js\r\n *\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.cropping2D({cropping:[[2, 2], [2, 2]],\r\n *                                inputShape: [128, 128, 3]}));\r\n * //now output shape is [batch, 124, 124, 3]\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\r\nexport function cropping2D(args: Cropping2DLayerArgs) {\r\n  return new Cropping2D(args);\r\n}\r\n\r\n/**\r\n * Upsampling layer for 2D inputs.\r\n *\r\n * Repeats the rows and columns of the data\r\n * by size[0] and size[1] respectively.\r\n *\r\n *\r\n * Input shape:\r\n *    4D tensor with shape:\r\n *     - If `dataFormat` is `\"channelsLast\"`:\r\n *         `[batch, rows, cols, channels]`\r\n *     - If `dataFormat` is `\"channelsFirst\"`:\r\n *        `[batch, channels, rows, cols]`\r\n *\r\n * Output shape:\r\n *     4D tensor with shape:\r\n *     - If `dataFormat` is `\"channelsLast\"`:\r\n *        `[batch, upsampledRows, upsampledCols, channels]`\r\n *     - If `dataFormat` is `\"channelsFirst\"`:\r\n *         `[batch, channels, upsampledRows, upsampledCols]`\r\n *\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\r\nexport function upSampling2d(args: UpSampling2DLayerArgs) {\r\n  return new UpSampling2D(args);\r\n}\r\n\r\n// Convolutional(depthwise) Layers.\r\n\r\n/**\r\n * Depthwise separable 2D convolution.\r\n *\r\n * Depthwise Separable convolutions consists in performing just the first step\r\n * in a depthwise spatial convolution (which acts on each input channel\r\n * separately). The `depthMultplier` argument controls how many output channels\r\n * are generated per input channel in the depthwise step.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Convolutional', namespace: 'layers'}\r\n */\r\nexport function depthwiseConv2d(args: DepthwiseConv2DLayerArgs) {\r\n  return new DepthwiseConv2D(args);\r\n}\r\n\r\n// Basic Layers.\r\n\r\n/**\r\n * Applies an activation function to an output.\r\n *\r\n * This layer applies element-wise activation function.  Other layers, notably\r\n * `dense` can also apply activation functions.  Use this isolated activation\r\n * function to extract the values before and after the\r\n * activation. For instance:\r\n *\r\n * ```js\r\n * const input = tf.input({shape: [5]});\r\n * const denseLayer = tf.layers.dense({units: 1});\r\n * const activationLayer = tf.layers.activation({activation: 'relu6'});\r\n *\r\n * // Obtain the output symbolic tensors by applying the layers in order.\r\n * const denseOutput = denseLayer.apply(input);\r\n * const activationOutput = activationLayer.apply(denseOutput);\r\n *\r\n * // Create the model based on the inputs.\r\n * const model = tf.model({\r\n *     inputs: input,\r\n *     outputs: [denseOutput, activationOutput]\r\n * });\r\n *\r\n * // Collect both outputs and print separately.\r\n * const [denseOut, activationOut] = model.predict(tf.randomNormal([6, 5]));\r\n * denseOut.print();\r\n * activationOut.print();\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function activation(args: ActivationLayerArgs) {\r\n  return new Activation(args);\r\n}\r\n\r\n/**\r\n * Creates a dense (fully connected) layer.\r\n *\r\n * This layer implements the operation:\r\n *   `output = activation(dot(input, kernel) + bias)`\r\n *\r\n * `activation` is the element-wise activation function\r\n *   passed as the `activation` argument.\r\n *\r\n * `kernel` is a weights matrix created by the layer.\r\n *\r\n * `bias` is a bias vector created by the layer (only applicable if `useBias`\r\n * is `true`).\r\n *\r\n * **Input shape:**\r\n *\r\n *   nD `tf.Tensor` with shape: `(batchSize, ..., inputDim)`.\r\n *\r\n *   The most common situation would be\r\n *   a 2D input with shape `(batchSize, inputDim)`.\r\n *\r\n * **Output shape:**\r\n *\r\n *   nD tensor with shape: `(batchSize, ..., units)`.\r\n *\r\n *   For instance, for a 2D input with shape `(batchSize, inputDim)`,\r\n *   the output would have shape `(batchSize, units)`.\r\n *\r\n * Note: if the input to the layer has a rank greater than 2, then it is\r\n * flattened prior to the initial dot product with the kernel.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function dense(args: DenseLayerArgs) {\r\n  return new Dense(args);\r\n}\r\n\r\n/**\r\n * Applies\r\n * [dropout](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf) to\r\n * the input.\r\n *\r\n * Dropout consists in randomly setting a fraction `rate` of input units to 0 at\r\n * each update during training time, which helps prevent overfitting.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function dropout(args: DropoutLayerArgs) {\r\n  return new Dropout(args);\r\n}\r\n\r\n/**\r\n * Spatial 1D version of Dropout.\r\n *\r\n * This Layer type performs the same function as the Dropout layer, but it drops\r\n * entire 1D feature maps instead of individual elements. For example, if an\r\n * input example consists of 3 timesteps and the feature map for each timestep\r\n * has a size of 4, a `spatialDropout1d` layer may zero out the feature maps\r\n * of the 1st timesteps and 2nd timesteps completely while sparing all feature\r\n * elements of the 3rd timestep.\r\n *\r\n * If adjacent frames (timesteps) are strongly correlated (as is normally the\r\n * case in early convolution layers), regular dropout will not regularize the\r\n * activation and will otherwise just result in merely an effective learning\r\n * rate decrease. In this case, `spatialDropout1d` will help promote\r\n * independence among feature maps and should be used instead.\r\n *\r\n * **Arguments:**\r\n *   rate: A floating-point number >=0 and <=1. Fraction of the input elements\r\n *     to drop.\r\n *\r\n * **Input shape:**\r\n *   3D tensor with shape `(samples, timesteps, channels)`.\r\n *\r\n * **Output shape:**\r\n *   Same as the input shape.\r\n *\r\n * References:\r\n *   - [Efficient Object Localization Using Convolutional\r\n *      Networks](https://arxiv.org/abs/1411.4280)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function spatialDropout1d(args: SpatialDropout1DLayerConfig) {\r\n  return new SpatialDropout1D(args);\r\n}\r\n\r\n/**\r\n * Flattens the input. Does not affect the batch size.\r\n *\r\n * A `Flatten` layer flattens each batch in its inputs to 1D (making the output\r\n * 2D).\r\n *\r\n * For example:\r\n *\r\n * ```js\r\n * const input = tf.input({shape: [4, 3]});\r\n * const flattenLayer = tf.layers.flatten();\r\n * // Inspect the inferred output shape of the flatten layer, which\r\n * // equals `[null, 12]`. The 2nd dimension is 4 * 3, i.e., the result of the\r\n * // flattening. (The 1st dimension is the undermined batch size.)\r\n * console.log(JSON.stringify(flattenLayer.apply(input).shape));\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function flatten(args?: FlattenLayerArgs) {\r\n  return new Flatten(args);\r\n}\r\n\r\n/**\r\n * Repeats the input n times in a new dimension.\r\n *\r\n * ```js\r\n *  const model = tf.sequential();\r\n *  model.add(tf.layers.repeatVector({n: 4, inputShape: [2]}));\r\n *  const x = tf.tensor2d([[10, 20]]);\r\n *  // Use the model to do inference on a data point the model hasn't see\r\n *  model.predict(x).print();\r\n *  // output shape is now [batch, 2, 4]\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function repeatVector(args: RepeatVectorLayerArgs) {\r\n  return new RepeatVector(args);\r\n}\r\n\r\n/**\r\n * Reshapes an input to a certain shape.\r\n *\r\n * ```js\r\n * const input = tf.input({shape: [4, 3]});\r\n * const reshapeLayer = tf.layers.reshape({targetShape: [2, 6]});\r\n * // Inspect the inferred output shape of the Reshape layer, which\r\n * // equals `[null, 2, 6]`. (The 1st dimension is the undermined batch size.)\r\n * console.log(JSON.stringify(reshapeLayer.apply(input).shape));\r\n * ```\r\n *\r\n * Input shape:\r\n *   Arbitrary, although all dimensions in the input shape must be fixed.\r\n *   Use the configuration `inputShape` when using this layer as the\r\n *   first layer in a model.\r\n *\r\n *\r\n * Output shape:\r\n *   [batchSize, targetShape[0], targetShape[1], ...,\r\n *    targetShape[targetShape.length - 1]].\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function reshape(args: ReshapeLayerArgs) {\r\n  return new Reshape(args);\r\n}\r\n\r\n/**\r\n * Permutes the dimensions of the input according to a given pattern.\r\n *\r\n * Useful for, e.g., connecting RNNs and convnets together.\r\n *\r\n * Example:\r\n *\r\n * ```js\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.permute({\r\n *   dims: [2, 1],\r\n *   inputShape: [10, 64]\r\n * }));\r\n * console.log(model.outputShape);\r\n * // Now model's output shape is [null, 64, 10], where null is the\r\n * // unpermuted sample (batch) dimension.\r\n * ```\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the configuration field `inputShape` when using this\r\n *   layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same rank as the input shape, but with the dimensions re-ordered (i.e.,\r\n *   permuted) according to the `dims` configuration of this layer.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function permute(args: PermuteLayerArgs) {\r\n  return new Permute(args);\r\n}\r\n\r\n/**\r\n * Maps positive integers (indices) into dense vectors of fixed size.\r\n * eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\r\n *\r\n * **Input shape:** 2D tensor with shape: `[batchSize, sequenceLength]`.\r\n *\r\n * **Output shape:** 3D tensor with shape: `[batchSize, sequenceLength,\r\n * outputDim]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Basic', namespace: 'layers'}\r\n */\r\nexport function embedding(args: EmbeddingLayerArgs) {\r\n  return new Embedding(args);\r\n}\r\n\r\n// Merge Layers.\r\n\r\n/**\r\n * Layer that performs element-wise addition on an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape, and returns a\r\n * single tensor (also of the same shape). The inputs are specified as an\r\n * `Array` when the `apply` method of the `Add` layer instance is called. For\r\n * example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const addLayer = tf.layers.add();\r\n * const sum = addLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(sum.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\r\nexport function add(args?: LayerArgs) {\r\n  return new Add(args);\r\n}\r\n\r\n/**\r\n * Layer that performs element-wise averaging on an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape, and returns a\r\n * single tensor (also of the same shape). For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const averageLayer = tf.layers.average();\r\n * const average = averageLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(average.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\r\nexport function average(args?: LayerArgs) {\r\n  return new Average(args);\r\n}\r\n\r\n/**\r\n * Layer that concatenates an `Array` of inputs.\r\n *\r\n * It takes a list of tensors, all of the same shape except for the\r\n * concatenation axis, and returns a single tensor, the concatenation\r\n * of all inputs. For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 3]});\r\n * const concatLayer = tf.layers.concatenate();\r\n * const output = concatLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(output.shape));\r\n * // You get [null, 2, 5], with the first dimension as the undetermined batch\r\n * // dimension. The last dimension (5) is the result of concatenating the\r\n * // last dimensions of the inputs (2 and 3).\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\r\nexport function concatenate(args?: ConcatenateLayerArgs) {\r\n  return new Concatenate(args);\r\n}\r\n\r\n/**\r\n * Layer that computes the element-wise maximum an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape and returns a\r\n * single tensor (also of the same shape). For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const maxLayer = tf.layers.maximum();\r\n * const max = maxLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(max.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\r\nexport function maximum(args?: LayerArgs) {\r\n  return new Maximum(args);\r\n}\r\n\r\n/**\r\n * Layer that computes the element-wise minimum of an `Array` of inputs.\r\n *\r\n * It takes as input a list of tensors, all of the same shape and returns a\r\n * single tensor (also of the same shape). For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const minLayer = tf.layers.minimum();\r\n * const min = minLayer.apply([input1, input2]);\r\n * console.log(JSON.stringify(min.shape));\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\r\nexport function minimum(args?: LayerArgs) {\r\n  return new Minimum(args);\r\n}\r\n\r\n/**\r\n * Layer that multiplies (element-wise) an `Array` of inputs.\r\n *\r\n * It takes as input an Array of tensors, all of the same\r\n * shape, and returns a single tensor (also of the same shape).\r\n * For example:\r\n *\r\n * ```js\r\n * const input1 = tf.input({shape: [2, 2]});\r\n * const input2 = tf.input({shape: [2, 2]});\r\n * const input3 = tf.input({shape: [2, 2]});\r\n * const multiplyLayer = tf.layers.multiply();\r\n * const product = multiplyLayer.apply([input1, input2, input3]);\r\n * console.log(product.shape);\r\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\r\n * // dimension.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\r\nexport function multiply(args?: LayerArgs) {\r\n  return new Multiply(args);\r\n}\r\n\r\n/**\r\n * Layer that computes a dot product between samples in two tensors.\r\n *\r\n * E.g., if applied to a list of two tensors `a` and `b` both of shape\r\n * `[batchSize, n]`, the output will be a tensor of shape `[batchSize, 1]`,\r\n * where each entry at index `[i, 0]` will be the dot product between\r\n * `a[i, :]` and `b[i, :]`.\r\n *\r\n * Example:\r\n *\r\n * ```js\r\n * const dotLayer = tf.layers.dot({axes: -1});\r\n * const x1 = tf.tensor2d([[10, 20], [30, 40]]);\r\n * const x2 = tf.tensor2d([[-1, -2], [-3, -4]]);\r\n *\r\n * // Invoke the layer's apply() method in eager (imperative) mode.\r\n * const y = dotLayer.apply([x1, x2]);\r\n * y.print();\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Merge', namespace: 'layers'}\r\n */\r\nexport function dot(args: DotLayerArgs) {\r\n  return new Dot(args);\r\n}\r\n\r\n// Normalization Layers.\r\n\r\n/**\r\n * Batch normalization layer (Ioffe and Szegedy, 2014).\r\n *\r\n * Normalize the activations of the previous layer at each batch,\r\n * i.e. applies a transformation that maintains the mean activation\r\n * close to 0 and the activation standard deviation close to 1.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape` (Array of integers, does\r\n *   not include the sample axis) when calling the constructor of this class,\r\n *   if this layer is used as a first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * References:\r\n *   - [Batch Normalization: Accelerating Deep Network Training by Reducing\r\n * Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Normalization', namespace: 'layers'}\r\n */\r\nexport function batchNormalization(args?: BatchNormalizationLayerArgs) {\r\n  return new BatchNormalization(args);\r\n}\r\n\r\n/**\r\n * Layer-normalization layer (Ba et al., 2016).\r\n *\r\n * Normalizes the activations of the previous layer for each given example in a\r\n * batch independently, instead of across a batch like in `batchNormalization`.\r\n * In other words, this layer applies a transformation that maintanis the mean\r\n * activation within each example close to0 and activation variance close to 1.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the argument `inputShape` when using this layer as the first\r\n *   layer in a model.\r\n *\r\n * Output shape:\r\n *   Same as input.\r\n *\r\n * References:\r\n *   - [Layer Normalization](https://arxiv.org/abs/1607.06450)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Normalization', namespace: 'layers'}\r\n */\r\nexport function layerNormalization(args?: LayerNormalizationLayerArgs) {\r\n  return new LayerNormalization(args);\r\n}\r\n\r\n// Padding Layers.\r\n\r\n/**\r\n * Zero-padding layer for 2D input (e.g., image).\r\n *\r\n * This layer can add rows and columns of zeros\r\n * at the top, bottom, left and right side of an image tensor.\r\n *\r\n * Input shape:\r\n *   4D tensor with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, rows, cols, channels]`\r\n *   - If `data_format` is `\"channels_first\"`:\r\n *     `[batch, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   4D with shape:\r\n *   - If `dataFormat` is `\"channelsLast\"`:\r\n *     `[batch, paddedRows, paddedCols, channels]`\r\n *    - If `dataFormat` is `\"channelsFirst\"`:\r\n *     `[batch, channels, paddedRows, paddedCols]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Padding', namespace: 'layers'}\r\n */\r\nexport function zeroPadding2d(args?: ZeroPadding2DLayerArgs) {\r\n  return new ZeroPadding2D(args);\r\n}\r\n\r\n// Pooling Layers.\r\n\r\n/**\r\n * Average pooling operation for spatial data.\r\n *\r\n * Input shape: `[batchSize, inLength, channels]`\r\n *\r\n * Output shape: `[batchSize, pooledLength, channels]`\r\n *\r\n * `tf.avgPool1d` is an alias.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function averagePooling1d(args: Pooling1DLayerArgs) {\r\n  return new AveragePooling1D(args);\r\n}\r\nexport function avgPool1d(args: Pooling1DLayerArgs) {\r\n  return averagePooling1d(args);\r\n}\r\n// For backwards compatibility.\r\n// See https://github.com/tensorflow/tfjs/issues/152\r\nexport function avgPooling1d(args: Pooling1DLayerArgs) {\r\n  return averagePooling1d(args);\r\n}\r\n\r\n/**\r\n * Average pooling operation for spatial data.\r\n *\r\n * Input shape:\r\n *  - If `dataFormat === CHANNEL_LAST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, rows, cols, channels]`\r\n *  - If `dataFormat === CHANNEL_FIRST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, channels, rows, cols]`\r\n *\r\n * Output shape\r\n *  - If `dataFormat === CHANNEL_LAST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, pooleRows, pooledCols, channels]`\r\n *  - If `dataFormat === CHANNEL_FIRST`:\r\n *      4D tensor with shape:\r\n *      `[batchSize, channels, pooleRows, pooledCols]`\r\n *\r\n * `tf.avgPool2d` is an alias.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function averagePooling2d(args: Pooling2DLayerArgs) {\r\n  return new AveragePooling2D(args);\r\n}\r\nexport function avgPool2d(args: Pooling2DLayerArgs) {\r\n  return averagePooling2d(args);\r\n}\r\n// For backwards compatibility.\r\n// See https://github.com/tensorflow/tfjs/issues/152\r\nexport function avgPooling2d(args: Pooling2DLayerArgs) {\r\n  return averagePooling2d(args);\r\n}\r\n\r\n/**\r\n * Average pooling operation for 3D data.\r\n *\r\n * Input shape\r\n *   - If `dataFormat === channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, depths, rows, cols, channels]`\r\n *   - If `dataFormat === channelsFirst`:\r\n *      4D tensor with shape:\r\n *       `[batchSize, channels, depths, rows, cols]`\r\n *\r\n * Output shape\r\n *   - If `dataFormat=channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, pooledDepths, pooledRows, pooledCols, channels]`\r\n *   - If `dataFormat=channelsFirst`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, channels, pooledDepths, pooledRows, pooledCols]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function averagePooling3d(args: Pooling3DLayerArgs) {\r\n  return new AveragePooling3D(args);\r\n}\r\nexport function avgPool3d(args: Pooling3DLayerArgs) {\r\n  return averagePooling3d(args);\r\n}\r\n// For backwards compatibility.\r\n// See https://github.com/tensorflow/tfjs/issues/152\r\nexport function avgPooling3d(args: Pooling3DLayerArgs) {\r\n  return averagePooling3d(args);\r\n}\r\n\r\n/**\r\n * Global average pooling operation for temporal data.\r\n *\r\n * Input Shape: 3D tensor with shape: `[batchSize, steps, features]`.\r\n *\r\n * Output Shape:2D tensor with shape: `[batchSize, features]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function globalAveragePooling1d(args?: LayerArgs) {\r\n  return new GlobalAveragePooling1D(args);\r\n}\r\n\r\n/**\r\n * Global average pooling operation for spatial data.\r\n *\r\n * Input shape:\r\n *   - If `dataFormat` is `CHANNEL_LAST`:\r\n *       4D tensor with shape: `[batchSize, rows, cols, channels]`.\r\n *   - If `dataFormat` is `CHANNEL_FIRST`:\r\n *       4D tensor with shape: `[batchSize, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   2D tensor with shape: `[batchSize, channels]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function globalAveragePooling2d(args: GlobalPooling2DLayerArgs) {\r\n  return new GlobalAveragePooling2D(args);\r\n}\r\n\r\n/**\r\n * Global max pooling operation for temporal data.\r\n *\r\n * Input Shape: 3D tensor with shape: `[batchSize, steps, features]`.\r\n *\r\n * Output Shape:2D tensor with shape: `[batchSize, features]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function globalMaxPooling1d(args?: LayerArgs) {\r\n  return new GlobalMaxPooling1D(args);\r\n}\r\n\r\n/**\r\n * Global max pooling operation for spatial data.\r\n *\r\n * Input shape:\r\n *   - If `dataFormat` is `CHANNEL_LAST`:\r\n *       4D tensor with shape: `[batchSize, rows, cols, channels]`.\r\n *   - If `dataFormat` is `CHANNEL_FIRST`:\r\n *       4D tensor with shape: `[batchSize, channels, rows, cols]`.\r\n *\r\n * Output shape:\r\n *   2D tensor with shape: `[batchSize, channels]`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function globalMaxPooling2d(args: GlobalPooling2DLayerArgs) {\r\n  return new GlobalMaxPooling2D(args);\r\n}\r\n\r\n/**\r\n * Max pooling operation for temporal data.\r\n *\r\n * Input shape:  `[batchSize, inLength, channels]`\r\n *\r\n * Output shape: `[batchSize, pooledLength, channels]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function maxPooling1d(args: Pooling1DLayerArgs) {\r\n  return new MaxPooling1D(args);\r\n}\r\n\r\n/**\r\n * Max pooling operation for spatial data.\r\n *\r\n * Input shape\r\n *   - If `dataFormat === CHANNEL_LAST`:\r\n *       4D tensor with shape:\r\n *       `[batchSize, rows, cols, channels]`\r\n *   - If `dataFormat === CHANNEL_FIRST`:\r\n *      4D tensor with shape:\r\n *       `[batchSize, channels, rows, cols]`\r\n *\r\n * Output shape\r\n *   - If `dataFormat=CHANNEL_LAST`:\r\n *       4D tensor with shape:\r\n *       `[batchSize, pooleRows, pooledCols, channels]`\r\n *   - If `dataFormat=CHANNEL_FIRST`:\r\n *       4D tensor with shape:\r\n *       `[batchSize, channels, pooleRows, pooledCols]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function maxPooling2d(args: Pooling2DLayerArgs) {\r\n  return new MaxPooling2D(args);\r\n}\r\n\r\n/**\r\n * Max pooling operation for 3D data.\r\n *\r\n * Input shape\r\n *   - If `dataFormat === channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, depths, rows, cols, channels]`\r\n *   - If `dataFormat === channelsFirst`:\r\n *      5D tensor with shape:\r\n *       `[batchSize, channels, depths, rows, cols]`\r\n *\r\n * Output shape\r\n *   - If `dataFormat=channelsLast`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, pooledDepths, pooledRows, pooledCols, channels]`\r\n *   - If `dataFormat=channelsFirst`:\r\n *       5D tensor with shape:\r\n *       `[batchSize, channels, pooledDepths, pooledRows, pooledCols]`\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Pooling', namespace: 'layers'}\r\n */\r\nexport function maxPooling3d(args: Pooling3DLayerArgs) {\r\n  return new MaxPooling3D(args);\r\n}\r\n\r\n// Recurrent Layers.\r\n\r\n/**\r\n * Gated Recurrent Unit - Cho et al. 2014.\r\n *\r\n * This is an `RNN` layer consisting of one `GRUCell`. However, unlike\r\n * the underlying `GRUCell`, the `apply` method of `SimpleRNN` operates\r\n * on a sequence of inputs. The shape of the input (not including the first,\r\n * batch dimension) needs to be at least 2-D, with the first dimension being\r\n * time steps. For example:\r\n *\r\n * ```js\r\n * const rnn = tf.layers.gru({units: 8, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the `GRUCell`'s number of units.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function gru(args: GRULayerArgs) {\r\n  return new GRU(args);\r\n}\r\n\r\n/**\r\n * Cell class for `GRU`.\r\n *\r\n * `GRUCell` is distinct from the `RNN` subclass `GRU` in that its\r\n * `apply` method takes the input data of only a single time step and returns\r\n * the cell's output at the time step, while `GRU` takes the input data\r\n * over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const cell = tf.layers.gruCell({units: 2});\r\n * const input = tf.input({shape: [10]});\r\n * const output = cell.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10]: This is the cell's output at a single time step. The 1st\r\n * // dimension is the unknown batch size.\r\n * ```\r\n *\r\n * Instance(s) of `GRUCell` can be used to construct `RNN` layers. The\r\n * most typical use of this workflow is to combine a number of cells into a\r\n * stacked RNN cell (i.e., `StackedRNNCell` internally) and use it to create an\r\n * RNN. For example:\r\n *\r\n * ```js\r\n * const cells = [\r\n *   tf.layers.gruCell({units: 4}),\r\n *   tf.layers.gruCell({units: 8}),\r\n * ];\r\n * const rnn = tf.layers.rnn({cell: cells, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps and a length-20 vector at each step.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the last `gruCell`'s number of units.\r\n * ```\r\n *\r\n * To create an `RNN` consisting of only *one* `GRUCell`, use the\r\n * `tf.layers.gru`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function gruCell(args: GRUCellLayerArgs) {\r\n  return new GRUCell(args);\r\n}\r\n\r\n/**\r\n * Long-Short Term Memory layer - Hochreiter 1997.\r\n *\r\n * This is an `RNN` layer consisting of one `LSTMCell`. However, unlike\r\n * the underlying `LSTMCell`, the `apply` method of `LSTM` operates\r\n * on a sequence of inputs. The shape of the input (not including the first,\r\n * batch dimension) needs to be at least 2-D, with the first dimension being\r\n * time steps. For example:\r\n *\r\n * ```js\r\n * const lstm = tf.layers.lstm({units: 8, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = lstm.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the `LSTMCell`'s number of units.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function lstm(args: LSTMLayerArgs) {\r\n  return new LSTM(args);\r\n}\r\n\r\n/**\r\n * Cell class for `LSTM`.\r\n *\r\n * `LSTMCell` is distinct from the `RNN` subclass `LSTM` in that its\r\n * `apply` method takes the input data of only a single time step and returns\r\n * the cell's output at the time step, while `LSTM` takes the input data\r\n * over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const cell = tf.layers.lstmCell({units: 2});\r\n * const input = tf.input({shape: [10]});\r\n * const output = cell.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10]: This is the cell's output at a single time step. The 1st\r\n * // dimension is the unknown batch size.\r\n * ```\r\n *\r\n * Instance(s) of `LSTMCell` can be used to construct `RNN` layers. The\r\n * most typical use of this workflow is to combine a number of cells into a\r\n * stacked RNN cell (i.e., `StackedRNNCell` internally) and use it to create an\r\n * RNN. For example:\r\n *\r\n * ```js\r\n * const cells = [\r\n *   tf.layers.lstmCell({units: 4}),\r\n *   tf.layers.lstmCell({units: 8}),\r\n * ];\r\n * const rnn = tf.layers.rnn({cell: cells, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps and a length-20 vector at each step.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the last `lstmCell`'s number of units.\r\n * ```\r\n *\r\n * To create an `RNN` consisting of only *one* `LSTMCell`, use the\r\n * `tf.layers.lstm`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function lstmCell(args: LSTMCellLayerArgs) {\r\n  return new LSTMCell(args);\r\n}\r\n\r\n/**\r\n * Fully-connected RNN where the output is to be fed back to input.\r\n *\r\n * This is an `RNN` layer consisting of one `SimpleRNNCell`. However, unlike\r\n * the underlying `SimpleRNNCell`, the `apply` method of `SimpleRNN` operates\r\n * on a sequence of inputs. The shape of the input (not including the first,\r\n * batch dimension) needs to be at least 2-D, with the first dimension being\r\n * time steps. For example:\r\n *\r\n * ```js\r\n * const rnn = tf.layers.simpleRNN({units: 8, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the `SimpleRNNCell`'s number of units.\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function simpleRNN(args: SimpleRNNLayerArgs) {\r\n  return new SimpleRNN(args);\r\n}\r\n\r\n/**\r\n * Cell class for `SimpleRNN`.\r\n *\r\n * `SimpleRNNCell` is distinct from the `RNN` subclass `SimpleRNN` in that its\r\n * `apply` method takes the input data of only a single time step and returns\r\n * the cell's output at the time step, while `SimpleRNN` takes the input data\r\n * over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const cell = tf.layers.simpleRNNCell({units: 2});\r\n * const input = tf.input({shape: [10]});\r\n * const output = cell.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10]: This is the cell's output at a single time step. The 1st\r\n * // dimension is the unknown batch size.\r\n * ```\r\n *\r\n * Instance(s) of `SimpleRNNCell` can be used to construct `RNN` layers. The\r\n * most typical use of this workflow is to combine a number of cells into a\r\n * stacked RNN cell (i.e., `StackedRNNCell` internally) and use it to create an\r\n * RNN. For example:\r\n *\r\n * ```js\r\n * const cells = [\r\n *   tf.layers.simpleRNNCell({units: 4}),\r\n *   tf.layers.simpleRNNCell({units: 8}),\r\n * ];\r\n * const rnn = tf.layers.rnn({cell: cells, returnSequences: true});\r\n *\r\n * // Create an input with 10 time steps and a length-20 vector at each step.\r\n * const input = tf.input({shape: [10, 20]});\r\n * const output = rnn.apply(input);\r\n *\r\n * console.log(JSON.stringify(output.shape));\r\n * // [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension is the\r\n * // same as the sequence length of `input`, due to `returnSequences`: `true`;\r\n * // 3rd dimension is the last `SimpleRNNCell`'s number of units.\r\n * ```\r\n *\r\n * To create an `RNN` consisting of only *one* `SimpleRNNCell`, use the\r\n * `tf.layers.simpleRNN`.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function simpleRNNCell(args: SimpleRNNCellLayerArgs) {\r\n  return new SimpleRNNCell(args);\r\n}\r\n\r\n/**\r\n * Convolutional LSTM layer - Xingjian Shi 2015.\r\n *\r\n * This is an `ConvRNN2D` layer consisting of one `ConvLSTM2DCell`. However,\r\n * unlike the underlying `ConvLSTM2DCell`, the `apply` method of `ConvLSTM2D`\r\n * operates on a sequence of inputs. The shape of the input (not including the\r\n * first, batch dimension) needs to be 4-D, with the first dimension being time\r\n * steps. For example:\r\n *\r\n * ```js\r\n * const filters = 3;\r\n * const kernelSize = 3;\r\n *\r\n * const batchSize = 4;\r\n * const sequenceLength = 2;\r\n * const size = 5;\r\n * const channels = 3;\r\n *\r\n * const inputShape = [batchSize, sequenceLength, size, size, channels];\r\n * const input = tf.ones(inputShape);\r\n *\r\n * const layer = tf.layers.convLstm2d({filters, kernelSize});\r\n *\r\n * const output = layer.apply(input);\r\n * ```\r\n */\r\n/** @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'} */\r\nexport function convLstm2d(args: ConvLSTM2DArgs) {\r\n  return new ConvLSTM2D(args);\r\n}\r\n\r\n/**\r\n * Cell class for `ConvLSTM2D`.\r\n *\r\n * `ConvLSTM2DCell` is distinct from the `ConvRNN2D` subclass `ConvLSTM2D` in\r\n * that its `call` method takes the input data of only a single time step and\r\n * returns the cell's output at the time step, while `ConvLSTM2D` takes the\r\n * input data over a number of time steps. For example:\r\n *\r\n * ```js\r\n * const filters = 3;\r\n * const kernelSize = 3;\r\n *\r\n * const sequenceLength = 1;\r\n * const size = 5;\r\n * const channels = 3;\r\n *\r\n * const inputShape = [sequenceLength, size, size, channels];\r\n * const input = tf.ones(inputShape);\r\n *\r\n * const cell = tf.layers.convLstm2dCell({filters, kernelSize});\r\n *\r\n * cell.build(input.shape);\r\n *\r\n * const outputSize = size - kernelSize + 1;\r\n * const outShape = [sequenceLength, outputSize, outputSize, filters];\r\n *\r\n * const initialH = tf.zeros(outShape);\r\n * const initialC = tf.zeros(outShape);\r\n *\r\n * const [o, h, c] = cell.call([input, initialH, initialC], {});\r\n * ```\r\n */\r\n/** @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'} */\r\nexport function convLstm2dCell(args: ConvLSTM2DCellArgs) {\r\n  return new ConvLSTM2DCell(args);\r\n}\r\n\r\n/**\r\n * Base class for recurrent layers.\r\n *\r\n * Input shape:\r\n *   3D tensor with shape `[batchSize, timeSteps, inputDim]`.\r\n *\r\n * Output shape:\r\n *   - if `returnState`, an Array of tensors (i.e., `tf.Tensor`s). The first\r\n *     tensor is the output. The remaining tensors are the states at the\r\n *     last time step, each with shape `[batchSize, units]`.\r\n *   - if `returnSequences`, the output will have shape\r\n *     `[batchSize, timeSteps, units]`.\r\n *   - else, the output will have shape `[batchSize, units]`.\r\n *\r\n * Masking:\r\n *   This layer supports masking for input data with a variable number\r\n *   of timesteps. To introduce masks to your data,\r\n *   use an embedding layer with the `mask_zero` parameter\r\n *   set to `True`.\r\n *\r\n * Notes on using statefulness in RNNs:\r\n *   You can set RNN layers to be 'stateful', which means that the states\r\n *   computed for the samples in one batch will be reused as initial states\r\n *   for the samples in the next batch. This assumes a one-to-one mapping\r\n *   between samples in different successive batches.\r\n *\r\n *   To enable statefulness:\r\n *     - specify `stateful: true` in the layer constructor.\r\n *     - specify a fixed batch size for your model, by passing\r\n *       if sequential model:\r\n *         `batchInputShape=[...]` to the first layer in your model.\r\n *       else for functional model with 1 or more Input layers:\r\n *         `batchShape=[...]` to all the first layers in your model.\r\n *       This is the expected shape of your inputs *including the batch size*.\r\n *       It should be a tuple of integers, e.g. `(32, 10, 100)`.\r\n *     - specify `shuffle=False` when calling fit().\r\n *\r\n *   To reset the states of your model, call `.resetStates()` on either\r\n *   a specific layer, or on your entire model.\r\n *\r\n * Note on specifying the initial state of RNNs\r\n *   You can specify the initial state of RNN layers symbolically by\r\n *   calling them with the option `initialState`. The value of\r\n *   `initialState` should be a tensor or list of tensors representing\r\n *   the initial state of the RNN layer.\r\n *\r\n *   You can specify the initial state of RNN layers numerically by\r\n *   calling `resetStates` with the keyword argument `states`. The value of\r\n *   `states` should be a numpy array or list of numpy arrays representing\r\n *   the initial state of the RNN layer.\r\n *\r\n * Note on passing external constants to RNNs\r\n *   You can pass \"external\" constants to the cell using the `constants`\r\n *   keyword argument of `RNN.call` method. This requires that the `cell.call`\r\n *   method accepts the same keyword argument `constants`. Such constants\r\n *   can be used to conditon the cell transformation on additional static inputs\r\n *   (not changing over time), a.k.a an attention mechanism.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function rnn(args: RNNLayerArgs) {\r\n  return new RNN(args);\r\n}\r\n\r\n/**\r\n * Wrapper allowing a stack of RNN cells to behave as a single cell.\r\n *\r\n * Used to implement efficient stacked RNNs.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Recurrent', namespace: 'layers'}\r\n */\r\nexport function stackedRNNCells(args: StackedRNNCellsArgs){\r\n  return new StackedRNNCells(args);\r\n}\r\n\r\n// Wrapper Layers.\r\n\r\n/** @doc {heading: 'Layers', subheading: 'Wrapper', namespace: 'layers'} */\r\nexport function bidirectional(args: BidirectionalLayerArgs) {\r\n  return new Bidirectional(args);\r\n}\r\n\r\n/**\r\n * This wrapper applies a layer to every temporal slice of an input.\r\n *\r\n * The input should be at least 3D,  and the dimension of the index `1` will be\r\n * considered to be the temporal dimension.\r\n *\r\n * Consider a batch of 32 samples, where each sample is a sequence of 10 vectors\r\n * of 16 dimensions. The batch input shape of the layer is then `[32,  10,\r\n * 16]`, and the `inputShape`, not including the sample dimension, is\r\n * `[10, 16]`.\r\n *\r\n * You can then use `TimeDistributed` to apply a `Dense` layer to each of the 10\r\n * timesteps, independently:\r\n *\r\n * ```js\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.timeDistributed({\r\n *   layer: tf.layers.dense({units: 8}),\r\n *   inputShape: [10, 16],\r\n * }));\r\n *\r\n * // Now model.outputShape = [null, 10, 8].\r\n * // The output will then have shape `[32, 10, 8]`.\r\n *\r\n * // In subsequent layers, there is no need for `inputShape`:\r\n * model.add(tf.layers.timeDistributed({layer: tf.layers.dense({units: 32})}));\r\n * console.log(JSON.stringify(model.outputs[0].shape));\r\n * // Now model.outputShape = [null, 10, 32].\r\n * ```\r\n *\r\n * The output will then have shape `[32, 10, 32]`.\r\n *\r\n * `TimeDistributed` can be used with arbitrary layers, not just `Dense`, for\r\n * instance a `Conv2D` layer.\r\n *\r\n * ```js\r\n * const model = tf.sequential();\r\n * model.add(tf.layers.timeDistributed({\r\n *   layer: tf.layers.conv2d({filters: 64, kernelSize: [3, 3]}),\r\n *   inputShape: [10, 299, 299, 3],\r\n * }));\r\n * console.log(JSON.stringify(model.outputs[0].shape));\r\n * ```\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Wrapper', namespace: 'layers'}\r\n */\r\nexport function timeDistributed(args: WrapperLayerArgs) {\r\n  return new TimeDistributed(args);\r\n}\r\n\r\n// Aliases for pooling.\r\nexport const globalMaxPool1d = globalMaxPooling1d;\r\nexport const globalMaxPool2d = globalMaxPooling2d;\r\nexport const maxPool1d = maxPooling1d;\r\nexport const maxPool2d = maxPooling2d;\r\n\r\nexport {Layer, RNN, RNNCell, input /* alias for tf.input */};\r\n\r\n/**\r\n * Apply additive zero-centered Gaussian noise.\r\n *\r\n * As it is a regularization layer, it is only active at training time.\r\n *\r\n * This is useful to mitigate overfitting\r\n * (you could see it as a form of random data augmentation).\r\n * Gaussian Noise (GS) is a natural choice as corruption process\r\n * for real valued inputs.\r\n *\r\n * # Arguments\r\n *     stddev: float, standard deviation of the noise distribution.\r\n *\r\n * # Input shape\r\n *         Arbitrary. Use the keyword argument `input_shape`\r\n *         (tuple of integers, does not include the samples axis)\r\n *         when using this layer as the first layer in a model.\r\n *\r\n * # Output shape\r\n *         Same shape as input.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Noise', namespace: 'layers'}\r\n */\r\nexport function gaussianNoise(args: GaussianNoiseArgs) {\r\n  return new GaussianNoise(args);\r\n}\r\n\r\n/**\r\n * Apply multiplicative 1-centered Gaussian noise.\r\n *\r\n * As it is a regularization layer, it is only active at training time.\r\n *\r\n * Arguments:\r\n *   - `rate`: float, drop probability (as with `Dropout`).\r\n *     The multiplicative noise will have\r\n *     standard deviation `sqrt(rate / (1 - rate))`.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape`\r\n *   (tuple of integers, does not include the samples axis)\r\n *   when using this layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * References:\r\n *   - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\r\n *      http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Noise', namespace: 'layers'}\r\n */\r\nexport function gaussianDropout(args: GaussianDropoutArgs) {\r\n  return new GaussianDropout(args);\r\n}\r\n\r\n/**\r\n * Applies Alpha Dropout to the input.\r\n *\r\n * As it is a regularization layer, it is only active at training time.\r\n *\r\n * Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\r\n * to their original values, in order to ensure the self-normalizing property\r\n * even after this dropout.\r\n * Alpha Dropout fits well to Scaled Exponential Linear Units\r\n * by randomly setting activations to the negative saturation value.\r\n *\r\n * Arguments:\r\n *   - `rate`: float, drop probability (as with `Dropout`).\r\n *     The multiplicative noise will have\r\n *     standard deviation `sqrt(rate / (1 - rate))`.\r\n *   - `noise_shape`: A 1-D `Tensor` of type `int32`, representing the\r\n *     shape for randomly generated keep/drop flags.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape`\r\n *   (tuple of integers, does not include the samples axis)\r\n *   when using this layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * References:\r\n *   - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Noise', namespace: 'layers'}\r\n */\r\nexport function alphaDropout(args: AlphaDropoutArgs) {\r\n  return new AlphaDropout(args);\r\n}\r\n\r\n/**\r\n * Masks a sequence by using a mask value to skip timesteps.\r\n *\r\n * If all features for a given sample timestep are equal to `mask_value`,\r\n * then the sample timestep will be masked (skipped) in all downstream layers\r\n * (as long as they support masking).\r\n *\r\n * If any downstream layer does not support masking yet receives such\r\n * an input mask, an exception will be raised.\r\n *\r\n * Arguments:\r\n *   - `maskValue`: Either None or mask value to skip.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape`\r\n *   (tuple of integers, does not include the samples axis)\r\n *   when using this layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * @doc {heading: 'Layers', subheading: 'Mask', namespace: 'layers'}\r\n */\r\nexport function masking(args?: MaskingArgs) {\r\n  return new Masking(args);\r\n}\r\n"},"lineCount":null}},"error":null,"hash":"2b0c592b0c15fa4b3fb5a02a074fbe15","cacheData":{"env":{}}}